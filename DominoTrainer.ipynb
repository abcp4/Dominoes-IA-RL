{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "%load_ext Cython\n",
    "import random\n",
    "from random import randrange\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import sys\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy\n",
    "cpdef cysum(numpy.ndarray[double] A,numpy.ndarray[double] B):\n",
    "    \"\"\"Compute the sum of an array\"\"\"\n",
    "    cdef int count=0\n",
    "    smax = B.shape[0]\n",
    "    \n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(i,A.shape[0]):\n",
    "            if(A[i]==1 and A[j]==1):\n",
    "                B[count] = 1\n",
    "            else:\n",
    "                B[count] = 0    \n",
    "            count = count + 1\n",
    "    return B\n",
    "cpdef threecysum(numpy.ndarray[double] A,numpy.ndarray[double] B):\n",
    "    \"\"\"Compute the sum of an array\"\"\"\n",
    "    cdef int count=0\n",
    "    smax = B.shape[0]\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(i,A.shape[0]):\n",
    "            for k in range(j,A.shape[0]):\n",
    "                if((A[i]==1 and A[j]==1) or(A[i]==1 and A[j]==1 and A[k]==1)):\n",
    "                    B[count] = 1\n",
    "                else:\n",
    "                    B[count] = 0    \n",
    "                count = count + 1\n",
    "    return B\n",
    "\n",
    "#combina 2 vetores num 3 vetor\n",
    "cpdef cyComb(numpy.ndarray[double] A,numpy.ndarray[double] B,numpy.ndarray[double] C,int x):    \n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(B.shape[0]):\n",
    "            if(A[i]==1 and B[j]==1):\n",
    "                C[x] = 1\n",
    "            x+=1\n",
    "    return [C,x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logica do jogo\n",
    "class Domino:  \n",
    "    def __init__(self,winReward,lostReward,blockingReward,blockedReward,lostPunition,gameType):\n",
    "        self.winReward = winReward\n",
    "        self.lostReward = lostReward\n",
    "        self.blockingReward = blockingReward\n",
    "        self.blockedReward = blockedReward\n",
    "        self.lostPunition = lostPunition\n",
    "        self.history = []\n",
    "        self.gameType = gameType\n",
    "        self.drawing = False\n",
    "        \n",
    "        \n",
    "    def buy(self,hand, n, pieces):\n",
    "        i = 0\n",
    "        while i<n:\n",
    "            hand.append(pieces[i])\n",
    "            i=i+1\n",
    "        del pieces[0:n]\n",
    "        return [hand,pieces]\n",
    "\n",
    "    #recebe estado do jogo, retorna ações possíveis\n",
    "    def possibleActions(self,state,player):\n",
    "        status = state[0]\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        boneyard = state[8]\n",
    "        actions = []\n",
    "        index = -1\n",
    "\n",
    "        if(l_end==r_end==-1):\n",
    "            for piece in hand:\n",
    "                index +=1\n",
    "                actions.append((piece[0],piece[1],index,\"hand\"))\n",
    "            return actions\n",
    "        \n",
    "        #para o game de block e draw\n",
    "        actions = self.checkMatch(hand,actions,l_end,r_end,\"hand\")\n",
    "        '''\n",
    "        pos 2 e 3 no actions se referem a nova ponta na mesa:\n",
    "        exemplo: campo 1-5 , mão : (1,2),(5,5)\n",
    "        nesse caso a peça (1,2) se encaixa no lado esquerdo, sendo\n",
    "        a nova ponta esquerda o 2. A representação será: (0,1), pois\n",
    "        0 é a posição da tupla na mão, e o 1 representa a posição na tupla,\n",
    "        que no caso é o direito\n",
    "\n",
    "        '''\n",
    "        #para o game de draw somente, caso tenha que comprar pecas\n",
    "        if(not actions and self.gameType == \"Draw\" ):\n",
    "            #print \"lol\"\n",
    "            #print actions\n",
    "            #print state\n",
    "            boneyard = state[8]\n",
    "            if(len(boneyard)>0):\n",
    "                actions = self.checkMatch(boneyard,actions,l_end,r_end,\"boneyard\") #busca no boneyard\n",
    "        if(not actions):\n",
    "            actions.append(None)\n",
    "        return actions\n",
    "    #action(valor significante,lado significante, posicao na hand ou boneyard, hand ou boneyard(se veio))\n",
    "    def checkMatch(self,pieces,actions,l_end,r_end,source):\n",
    "        index = -1\n",
    "        for piece in pieces:\n",
    "            index +=1\n",
    "            #peça dupla\n",
    "            if(piece[0]==piece[1]):\n",
    "                if(piece[0]==l_end):\n",
    "                    actions.append((piece[1],\"left\",index,source))\n",
    "                elif(piece[1]==r_end):\n",
    "                    actions.append((piece[0],\"right\",index,source))\n",
    "                continue\n",
    "            if(piece[0]==l_end):\n",
    "                actions.append((piece[1],\"left\",index,source))\n",
    "                if(l_end==r_end): #evitar duplicacao de mesmas ações na esq e dir\n",
    "                    continue\n",
    "            if(piece[1]==l_end):\n",
    "                actions.append((piece[0],\"left\",index,source))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[0]==r_end):\n",
    "                actions.append((piece[1],\"right\",index,source))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[1]==r_end):\n",
    "                actions.append((piece[0],\"right\",index,source))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "        return actions\n",
    "\n",
    "    def termination(self,state):#se a partida ja terminou\n",
    "        status = state[0]\n",
    "        if (status >= 3):\n",
    "            return True  \n",
    "        return False\n",
    "    \n",
    "    def reward(self,state,player):#recompensa por estar nesse estado\n",
    "        #em caso de vitoria\n",
    "        status = state[0]\n",
    "        p1_hand = state[1]\n",
    "        p2_hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if(status == 1):\n",
    "            return 0\n",
    "        \n",
    "        if((state[6] != state[7] ) and status < 3):#avaliar block    \n",
    "            if(state[6]):\n",
    "                if(player == \"p1\"):#fui bloqueado\n",
    "                    return self.blockedReward\n",
    "                else:\n",
    "                    return self.blockingReward\n",
    "            else:\n",
    "                if(player == \"p2\"):#fui bloqueado\n",
    "                    return self.blockedReward \n",
    "                else:\n",
    "                    return self.blockingReward\n",
    "            \n",
    "        if(status >= 3):\n",
    "            p1_hand = state[1]\n",
    "            p2_hand = state[2]\n",
    "            lighestP1Value = 13\n",
    "            lighestP2Value = 13\n",
    "            lighestP1Tile = 13\n",
    "            lighestP2Tile = 13\n",
    "            p1_total_value = 0\n",
    "            p2_total_value = 0\n",
    "            for piece in p1_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p1_total_value+=value\n",
    "            for piece in p2_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p2_total_value+=value             \n",
    "                \n",
    "            if(p1_total_value<p2_total_value):\n",
    "                state[0] = 4#player 1 venceu tendo a menor mao\n",
    "                if(player == \"p1\"):\n",
    "                    return self.winReward + p2_total_value\n",
    "                elif(self.lostPunition):# se é pra punir pq perdeu\n",
    "                    return self.lostReward - p2_total_value # punicao mais pontos que tinha\n",
    "                else:\n",
    "                    return 0\n",
    "                \n",
    "            elif(p1_total_value>p2_total_value):\n",
    "                state[0] = 5#player 2 venceu tendo a menor mao\n",
    "                if(player == \"p2\"):\n",
    "                    return self.winReward + p1_total_value\n",
    "                elif(self.lostPunition):\n",
    "                    return self.lostReward - p1_total_value\n",
    "                else:\n",
    "                    return 0\n",
    "            else:#empate\n",
    "                for piece in p1_hand:\n",
    "                    if(piece[0]<lighestP1Value):\n",
    "                        lighestP1Value = piece[0]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP1Value):\n",
    "                        lighestP1Value = piece[1]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                for piece in p2_hand:\n",
    "                    if(piece[0]<lighestP2Value):\n",
    "                        lighestP2Value = piece[0]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP2Value):\n",
    "                        lighestP2Value = piece[1]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                if(lighestP1Value<lighestP2Value):\n",
    "                    state[0] = 4#player 1 venceu tendo o menor valor entre o par das pecas    \n",
    "                    if(player == \"p1\"):\n",
    "                        return self.winReward + p2_total_value\n",
    "                    elif(self.lostPunition):\n",
    "                        return self.lostReward - p2_total_value\n",
    "                    else:\n",
    "                        return 0\n",
    "                elif(lighestP1Value>lighestP2Value):\n",
    "                    state[0] = 5#player 2 venceu tendo o menor valor entre o par das pecas\n",
    "                    if(player == \"p2\"):\n",
    "                        return self.winReward + p1_total_value \n",
    "                    elif(self.lostPunition):\n",
    "                        return self.lostReward - p1_total_value\n",
    "                    else:\n",
    "                        return 0\n",
    "                else:\n",
    "                    if(lighestP1Tile<lighestP2Tile):#menor valor da peça como um todo\n",
    "                        state[0] = 4\n",
    "                        if(player == \"p1\"):\n",
    "                            return self.winReward + p2_total_value\n",
    "                        elif(self.lostPunition):\n",
    "                            return self.lostReward - p2_total_value\n",
    "                        else:\n",
    "                            return 0\n",
    "                    else:#nao pode haver empate\n",
    "                        state[0] = 5\n",
    "                        if(player == \"p2\"):\n",
    "                            return self.winReward + p1_total_value \n",
    "                        elif(self.lostPunition):\n",
    "                            return self.lostReward - p1_total_value\n",
    "                        else:\n",
    "                            return 0\n",
    "\n",
    "    def undoHistory(self,state,player):#ele considera que o player foi o ult a jogar\n",
    "        if(len(self.history)>0):\n",
    "            action = self.history.pop()\n",
    "            if(action is None or action[0] is None):\n",
    "                if(state[0]==3):#N DEVE existir um estado de vitoria anterior a este\n",
    "                    state[0] = 1\n",
    "                    return state #ele sempre tera none antes da vitoria \n",
    "                if(state[0]==4 or state[0]==5):#caso ele avalie uma 2 vez dps do 3\n",
    "                    return state #ele n deve dar undo apos vitoria \n",
    "                if(len(self.history)>0):#\n",
    "                    action2 = self.history.pop()\n",
    "                    if(action2 is not None):#se ja n estava bloqueado\n",
    "                        if(player == \"p1\"):\n",
    "                            state[6] = False\n",
    "                        else:\n",
    "                            state[7] = False\n",
    "                    self.history.append(action2)\n",
    "                else:\n",
    "                    if(player == \"p1\"):#ninguem começa bloqueado\n",
    "                        state[6] = False\n",
    "                    else:\n",
    "                        state[7] = False\n",
    "                \n",
    "                    \n",
    "                return state     #o alg se encarrega de dar undo corretamente      \n",
    "                \n",
    "            field = state[3]\n",
    "            l_end = state[4]\n",
    "            r_end = state[5]\n",
    "            \n",
    "            #print \"Action taken out: \"+str(action)\n",
    "            #print self.history\n",
    "            #print state\n",
    "                \n",
    "            piece = field.pop()#nunca deve estar vazio,se estiver o problema e a historia\n",
    "            \n",
    "            if(state[0]==3):#TOMAR MUITO CUIDADO AKI\n",
    "                state[0] = 1\n",
    "            \n",
    "            if(player == \"p1\"):\n",
    "                hand = state[1]\n",
    "            else:\n",
    "                hand = state[2]\n",
    "            #print action\n",
    "            act = action[0]\n",
    "            pos = act[2]\n",
    "            if(len(self.history)>0):#se nao foi a 1 jogada\n",
    "                if(piece[0]!=piece[1]):#se n for peça dupla\n",
    "                    if(piece[0] == act[0]):\n",
    "                        if(act[1]==\"left\"):\n",
    "                            l_end = piece[1] #só pode ter o msm valor que o lado dela\n",
    "                        else:\n",
    "                            r_end = piece[1]\n",
    "                    elif(piece[1] == act[0]):\n",
    "                        if(act[1]==\"left\"):\n",
    "                            l_end = piece[0] #só pode ter o msm valor que o lado dela\n",
    "                        else:\n",
    "                            r_end = piece[0]        \n",
    "                else:\n",
    "                    if(act[1]==\"left\"):\n",
    "                        l_end = piece[1] #tomar cuidado aki, pra n conflitar com\n",
    "                    else:\n",
    "                        r_end = piece[1]# o tratamento a peças duplas na ação\n",
    "                hand.insert(pos,piece)\n",
    "                \n",
    "            else:\n",
    "                l_end = r_end = -1\n",
    "                hand.insert(pos,piece)\n",
    "            \n",
    "            if(player == \"p1\"):\n",
    "                state[1] = hand\n",
    "            else:\n",
    "                state[2] = hand\n",
    "                \n",
    "            state[3] = field\n",
    "            state[4] = l_end\n",
    "            state[5] = r_end\n",
    "            return state\n",
    "        else:\n",
    "            if(state[0]==3):#TOMAR MUITO CUIDADO AKI\n",
    "                state[0] = 1\n",
    "            return state\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    def startGame(self):\n",
    "        status = 1 #1=in progress; 2=one player blocked;3=two players blocked;4/5=p1 won/p2 won\n",
    "        boneyard = [(x,y) for x in range(7) for y in range(x,7)]\n",
    "        random.shuffle(boneyard)\n",
    "        p1_hand,boneyard = self.buy([],7,boneyard)\n",
    "        p2_hand,boneyard = self.buy([],7,boneyard)\n",
    "        field = []\n",
    "        l_end = -1\n",
    "        r_end = -1\n",
    "        player1Blocked = False\n",
    "        player2Blocked = False\n",
    "        self.history = []  \n",
    "        turn = 0 #turno de jogo que vai incrementando a cada jogada\n",
    "        #p2 hand n e visivel, mas o agente imperfeito pode utilizar len() para saber o \n",
    "        #tamanho da mao do oponente\n",
    "        state = [status, p1_hand, p2_hand, field,l_end,r_end,player1Blocked,player2Blocked,boneyard,turn]\n",
    "        return state\n",
    "\n",
    "    def playAction(self,state,action,player):\n",
    "        status = state[0]\n",
    "        if(status >= 3): #jogo acabou\n",
    "            return state\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "            \n",
    "        field = state[3]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        boneyard = state[8]\n",
    "\n",
    "        if(self.gameType==\"Draw\"):\n",
    "            if(action[0] is None):#nenhuma peca no boneyard e jogavel\n",
    "                if(player ==\"p1\"):\n",
    "                    state[1]+=state[8] #receba todas as pecas do boneyard\n",
    "                    state[8] = []\n",
    "                    state[6] = True\n",
    "                elif(player ==\"p2\"):\n",
    "                    state[2]+=state[8]\n",
    "                    state[8] = []\n",
    "                    state[7] = True\n",
    "                if(state[6] and state[7]): #ambos estao bloqueados\n",
    "                    state[0] = 3\n",
    "                return state\n",
    "            \n",
    "            else: \n",
    "                if(player ==\"p1\"):\n",
    "                    state[6] = False #se estava em block, nao esta mais\n",
    "                else:\n",
    "                    state[7] = False\n",
    "                p_index = action[2]  \n",
    "\n",
    "                if(l_end==r_end==-1):\n",
    "                    orientation = \"left\"\n",
    "                else:\n",
    "                    orientation = action[1]\n",
    "                if(action[3]==\"boneyard\"):#se ele esta jogando peca do boneyard\n",
    "                    #print \"action: \" + str(action)\n",
    "                    #print : \" + str(boneyard)\n",
    "                    p = boneyard[p_index]\n",
    "                    field.append(p)\n",
    "                    boneyard.remove(p) \n",
    "                else: \n",
    "                    #print \"action: \" + str(action)\n",
    "                    #print \"hand: \" + str(hand)\n",
    "                    p = hand[p_index]\n",
    "                    field.append(p)\n",
    "                    hand.remove(p)\n",
    "                \n",
    "                self.drawing = False\n",
    "                \n",
    "        elif(self.gameType==\"Block\"):\n",
    "            \n",
    "            if(action is None):#foi bloqueado\n",
    "                self.history.append(None)\n",
    "                if(player ==\"p1\"):\n",
    "                    state[6] = True\n",
    "                else:\n",
    "                    state[7] = True\n",
    "                if(state[6] and state[7]): #ambos estao bloqueados\n",
    "                    state[0] = 3\n",
    "                return state\n",
    "\n",
    "            if(action[0] is None):#foi bloqueado no block\n",
    "                self.history.append([action[0]])\n",
    "                if(player ==\"p1\"):\n",
    "                    state[6] = True\n",
    "                else:\n",
    "                    state[7] = True\n",
    "                if(state[6] and state[7]):\n",
    "                    state[0] = 3\n",
    "                return state \n",
    "        \n",
    "            #dado que o block acima n ocorreu, entao temos peca para nos livrar de um eventual block\n",
    "            if(player ==\"p1\"):\n",
    "                state[6] = False\n",
    "            else:\n",
    "                state[7] = False\n",
    "            p_index = action[2]  \n",
    "\n",
    "            if(l_end==r_end==-1):\n",
    "                orientation = \"left\"\n",
    "            else:\n",
    "                orientation = action[1]\n",
    "            \n",
    "            p = hand[p_index]\n",
    "            self.history.append([action])#action ja vem com a pos atualizada\n",
    "            field.append(p)\n",
    "            hand.remove(p)\n",
    "    \n",
    "        if(l_end==-1 and r_end==-1):\n",
    "            l_end, r_end = p\n",
    "        elif(orientation == \"right\"):#ori e o lado desejado a manter na ponta\n",
    "            r_end=action[0]\n",
    "        elif(orientation == \"left\"):\n",
    "            l_end=action[0]\n",
    "                \n",
    "        if(player ==\"p1\"):\n",
    "            state[1] = hand\n",
    "        else:\n",
    "            state[2] = hand\n",
    "            \n",
    "        if(len(hand) ==0): #zerou a mao, acabou o jogo\n",
    "            state[0] = 3\n",
    "            \n",
    "        state[3] = field\n",
    "        state[4] = l_end\n",
    "        state[5] = r_end\n",
    "        state[9] +=1 #incrementa 1 turno\n",
    "        return state#mecanica do jogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     65,
     75,
     83,
     90,
     99
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcoes auxiliares utilizadas pelo validator\n",
    "class Rules:\n",
    "    \n",
    "    def isTurn(self,turn,exp):\n",
    "        if(exp(turn)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def NumDouble(self,hand,action,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(piece[0] == piece[1]):\n",
    "                count +=1\n",
    "        if(exp(count)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def HandSize(self,hand,exp):\n",
    "        lenght = len(hand)\n",
    "        return exp(lenght)\n",
    "    \n",
    "    def hasDouble(self,number,hand):\n",
    "        for piece in hand:\n",
    "            if((piece[0] == piece[1]) and (piece[0] == number)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPiece(self,hand,myPiece):\n",
    "        for piece in hand:\n",
    "            if( myPiece == piece ):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPieceValue(self,hand,exp):\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasManyPieceValues(self,hand,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                count+=1\n",
    "        return count\n",
    "    \n",
    "    def hasHandValue(self,hand):\n",
    "        value = 0\n",
    "        for piece in hand:\n",
    "            value += piece[0] + piece[1]\n",
    "        return value\n",
    "    \n",
    "    def blocks(self,hand,l_end,r_end):\n",
    "        if(l_end==-1 or r_end==-1):\n",
    "            return False\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                #se encontra alguma peça valida na mao\n",
    "                return False # então ainda não estou bloqueado\n",
    "        return True #nao encontrou\n",
    "        \n",
    "         \n",
    "\n",
    "    def NumActions(self,hand,l_end,r_end):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                count +=1\n",
    "            if(self.specialCase(piece,l_end,r_end)):\n",
    "                count+=1 \n",
    "               \n",
    "        return count\n",
    "    \n",
    "    def shortPiece(self,number,handOp):\n",
    "        for piece in handOp:\n",
    "            if(piece[0]==number or piece[1]==number):\n",
    "                return False\n",
    "        return True #op n tem nenhuma peça dese tipo\n",
    "        \n",
    "          \n",
    "    \n",
    "    def hasSpecialCase(self,hand,l_end,r_end):\n",
    "        for piece in hand:\n",
    "            if((piece[0]==l_end and piece[1]==r_end) or (piece[0]==r_end and piece[1]==l_end)):\n",
    "                if(l_end!=r_end):\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def isPlayable(self,piece,l_end,r_end):#se dado a peça e as duas pontas, ela é jogavel\n",
    "        if(piece[0]==l_end or piece[0]==r_end or piece[1]==l_end or piece[1]==r_end):\n",
    "            return True\n",
    "        if(l_end == r_end == -1):\n",
    "            return True\n",
    "        return False   \n",
    "    \n",
    "    #tratar caso especial. Ex:\n",
    "    # l = 5, r = 4 , piece = (5,4) , acoes possiveis sao 2: (4,l) e (5,r)\n",
    "    def specialCase(self,piece,l_end,r_end):\n",
    "        if((piece[0]==l_end and piece[1]==r_end) or (piece[0]==r_end and piece[1]==l_end)):\n",
    "                if(l_end!=r_end):\n",
    "                    return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcoes auxiliares utilizadas pelo validator\n",
    "class Rules2:\n",
    "    \n",
    "    def isTurn(self,turn,exp):\n",
    "        if(exp(turn)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def NumDouble(self,hand,action,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(piece[0] == piece[1]):\n",
    "                count +=1\n",
    "        if(exp(count)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def HandSize(self,hand,exp):\n",
    "        lenght = len(hand)\n",
    "        return exp(lenght)\n",
    "    \n",
    "    def hasDouble(self,number,hand):\n",
    "        for piece in hand:\n",
    "            if((piece[0] == piece[1]) and (piece[0] == number)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPiece(self,hand,myPiece):\n",
    "        for piece in hand:\n",
    "            if( myPiece == piece ):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPieceValue(self,hand,exp):\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasManyPieceValues(self,hand,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                count+=1\n",
    "        return count\n",
    "    \n",
    "    def hasHandValue(self,hand,exp):\n",
    "        value = 0\n",
    "        for piece in hand:\n",
    "            value += piece[0] + piece[1]\n",
    "        if(exp(value)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def blocks(self,hand,l_end,r_end):\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                #se encontra alguma peça valida na mao\n",
    "                return False # então ainda não estou bloqueado\n",
    "        return True #nao encontrou\n",
    "        \n",
    "    def NumActions(self,hand,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                count +=1\n",
    "        if(exp(count)):#se tem mais que o numero de peças designado\n",
    "            return True\n",
    "        return False #se tem exatamente aquele numero\n",
    "    \n",
    "    def shortPiece(self,number,handOp):\n",
    "        for piece in handOp:\n",
    "            if(piece[0]==number or piece[1]==number):\n",
    "                return False\n",
    "        return True #op n tem nenhuma peça dese tipo\n",
    "        \n",
    "          \n",
    "    def isPlayable(self,piece,l_end,r_end):#se dado a peça e as duas pontas, ela é jogavel\n",
    "        if(piece[0]==l_end or piece[0]==r_end or piece[1]==l_end or piece[1]==r_end):\n",
    "            return True\n",
    "        return False   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RN 35 caracteristicas\n",
    "class Network:\n",
    "    def validate(self,result,hand,handOp,action,player,state):\n",
    "        rules = Rules2()\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        \"\"\"\n",
    "        Características a partir de informações imperfeitas.\n",
    "            Somente do que é visível a um jogador comum:\n",
    "                Campo, peças de suas mãos, quantidade de peças do oponente\n",
    "        \"\"\"\n",
    "        #valida caracteristicas de acordo com o estado submetido e as retorna\n",
    "\n",
    "        result[0] = rules.NumDouble(hand,action,l_end,r_end,lambda x: x==1)\n",
    "        result[1] = rules.NumDouble(hand,action,l_end,r_end,lambda x: x==2)\n",
    "        result[2] = rules.NumDouble(hand,action,l_end,r_end,lambda x: x>=3)\n",
    "        #impossibilita qualquer peça de ser jogada\n",
    "        result[3] = rules.blocks(hand,l_end,r_end)\n",
    "        \n",
    "        result[4] = rules.NumActions(hand,l_end,r_end,lambda x: x==1)\n",
    "        result[5] = rules.NumActions(hand,l_end,r_end,lambda x: x==2)\n",
    "        result[6] = rules.NumActions(hand,l_end,r_end,lambda x: x>=3)\n",
    "       \n",
    "        for i in range(7,14):\n",
    "            #quais peças op tem na mão, de 0 a 6\n",
    "            result[i] = rules.hasDouble(i-7,hand)\n",
    "                \n",
    "        \"\"\"\n",
    "        Perfect Information\n",
    "        \"\"\"\n",
    "        result[14] = rules.blocks(handOp,l_end,r_end)\n",
    "        result[15] = rules.NumActions(handOp,l_end,r_end,lambda x: x==1)\n",
    "        result[16] = rules.NumActions(handOp,l_end,r_end,lambda x: x==2)\n",
    "        result[17] = rules.NumActions(handOp,l_end,r_end,lambda x: x>=3)\n",
    "        for i in range(18,25):\n",
    "            #quais peças duplas temos na mão, de 0:0 a 6:6\n",
    "            result[i] = rules.shortPiece(i-18,handOp)\n",
    "        \n",
    "        \n",
    "        result[25] = rules.hasPieceValue(hand,lambda x: x>=9)\n",
    "        result[26] = rules.hasPieceValue(hand,lambda x: x<=3)\n",
    "        result[27] = rules.hasHandValue(hand,lambda x: x<=4)\n",
    "        result[28] = rules.hasHandValue(hand,lambda x: x>=12 and x<=19)\n",
    "        result[29] = rules.hasHandValue(hand,lambda x: x>=20)\n",
    "            \n",
    "        result[30] = rules.hasPieceValue(handOp,lambda x: x>=9)\n",
    "        result[31] = rules.hasPieceValue(handOp,lambda x: x<=3)\n",
    "        result[32] = rules.hasHandValue(handOp,lambda x: x<=4)\n",
    "        result[33] = rules.hasHandValue(handOp,lambda x: x>=12 and x<=19)\n",
    "        result[34] = rules.hasHandValue(handOp,lambda x: x>=20)\n",
    "                    \n",
    "        #result[35] = rules.HandSize(hand,lambda x: x<=3)\n",
    "        #result[36] = rules.HandSize(hand,lambda x: x>3)\n",
    "        #result[37] = rules.HandSize(handOp,lambda x: x<=3)\n",
    "        #result[38] = rules.HandSize(handOp,lambda x: x>3)\n",
    "        return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RN Muitas características\n",
    "class ExtensiveNetwork:\n",
    "     def validate(self,result,hand,handOp,action,player,state):\n",
    "        rules = Rules()\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        turn = state[9]\n",
    "        \n",
    "        #result = np.zeros(110)\n",
    "        result[0] = rules.blocks(hand,l_end,r_end)\n",
    "        \n",
    "        for i in range(1,8):\n",
    "            #quais peças op tem na mão, de 0 a 6\n",
    "            result[i] = rules.hasDouble(i-1,hand)\n",
    "            \n",
    "        result[8] = rules.blocks(handOp,l_end,r_end)\n",
    "        \n",
    "        myHandValue = rules.hasHandValue(hand)\n",
    "        result[9] = myHandValue<7\n",
    "        result[10] = myHandValue>=7 and myHandValue<=15\n",
    "        result[11] = myHandValue>15 and myHandValue<=25\n",
    "        result[12] = myHandValue>25 and myHandValue<=35\n",
    "        result[13] = myHandValue>35 and myHandValue<=47\n",
    "        result[14] = myHandValue>47\n",
    "        \n",
    "        opHandValue = rules.hasHandValue(handOp)\n",
    "        result[15] = opHandValue<7\n",
    "        result[16] = opHandValue>=7 and opHandValue<=15\n",
    "        result[17] = opHandValue>15 and opHandValue<=25\n",
    "        result[18] = opHandValue>25 and opHandValue<=35\n",
    "        result[19] = opHandValue>35 and opHandValue<=47\n",
    "        result[20] = myHandValue>47\n",
    "        #Esses valores altos(35 pra cima, sao a media pra uma mao com 7)\n",
    "        result[21] = rules.hasSpecialCase(hand,l_end,r_end)\n",
    "        result[22] = rules.hasSpecialCase(handOp,l_end,r_end)\n",
    "        j = 23\n",
    "        counter = 0\n",
    "        numAct = rules.NumActions(hand,l_end,r_end)\n",
    "        for i in range(j,j+6):\n",
    "            result[i] = numAct == counter\n",
    "            counter +=1\n",
    "        j+=counter\n",
    "        result[j] = numAct >= 6\n",
    "        j+=1\n",
    "        \n",
    "        counter = 0\n",
    "        numAct = rules.NumActions(hand,l_end,r_end)\n",
    "        for i in range(j,j+6):\n",
    "            result[i] = numAct == counter\n",
    "            counter +=1\n",
    "        j+=counter\n",
    "        result[j] = numAct >= 6\n",
    "        j+=1\n",
    "        #turnos\n",
    "        for i in range(13):\n",
    "            result[j] = rules.isTurn(turn,lambda x: x==i)\n",
    "            j+=1\n",
    "        result[j]  = rules.isTurn(turn,lambda x: x>13)\n",
    "        j+=1\n",
    "        manyPieceArray = np.zeros(28)\n",
    "        #count e a contagem de pecas diferentes com a soma dos valores respeitado a funcao\n",
    "        count1 = rules.hasManyPieceValues(hand,lambda x: x<3)\n",
    "        count2 = rules.hasManyPieceValues(hand,lambda x: x>=3 and x<=6)\n",
    "        count3 = rules.hasManyPieceValues(hand,lambda x: x>6 and x<=9)\n",
    "        count4 = rules.hasManyPieceValues(hand,lambda x: x>9)\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            result[j] = i == count1#de 1-6 pecas diferentes na mao com valor menor q 3\n",
    "            result[j+7] = i == count2#de 1-6 pecas diferentes na mao com valor entre 3 e 6\n",
    "            result[j+14] = i == count3#de 1-6 pecas diferentes na mao com valor entre 7 e 9\n",
    "            result[j+21] = i == count4#de 1-6 pecas diferentes na mao com valor maior que 9\n",
    "            j+=1\n",
    "        j += 21\n",
    "        manyPieceArray = np.zeros(28)\n",
    "        #count e a contagem de pecas diferentes com a soma dos valores respeitado a funcao\n",
    "        count1 = rules.hasManyPieceValues(handOp,lambda x: x<3)\n",
    "        count2 = rules.hasManyPieceValues(handOp,lambda x: x>=3 and x<=6)\n",
    "        count3 = rules.hasManyPieceValues(handOp,lambda x: x>6 and x<=9)\n",
    "        count4 = rules.hasManyPieceValues(handOp,lambda x: x>9)\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            result[j] = i == count1#de 1-6 pecas diferentes na mao com valor menor q 3\n",
    "            result[j+7] = i == count2#de 1-6 pecas diferentes na mao com valor entre 3 e 6\n",
    "            result[j+14] = i == count3#de 1-6 pecas diferentes na mao com valor entre 7 e 9\n",
    "            result[j+21] = i == count4#de 1-6 pecas diferentes na mao com valor maior que 9\n",
    "            j+=1\n",
    "        \n",
    "        j += 21\n",
    "        #threewise_result = threecysum(result,threewise_result)\n",
    "        #if(result[37]==1):\n",
    "            #print player\n",
    "            #print state \n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classe principal que computa as caracteristicas presentes numa RN\n",
    "class Features:\n",
    "    def __init__(self,featureWeights,featureValidator):\n",
    "        self.data = []\n",
    "        self.featureWeights = featureWeights\n",
    "        self.numFeatures = featureWeights.size\n",
    "        self.featureValidator = featureValidator\n",
    "           \n",
    "    def getFeaturesWeights(self):\n",
    "        return self.featureWeights\n",
    "    \n",
    "    def setFeaturesWeights(self,featureWeights):\n",
    "        self.featureWeights = featureWeights\n",
    "        \n",
    "    def atomicFeatures(self,state,action,player):\n",
    "        result =  np.zeros(self.numFeatures)\n",
    "        \n",
    "        #Trate como afterState\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if(player == \"p1\"):\n",
    "            hand = state[1]\n",
    "            handOp = state[2]\n",
    "        elif(player == \"p2\"):\n",
    "            hand = state[2]\n",
    "            handOp = state[1]\n",
    "        if(action is not None):\n",
    "            if(action[0]!=None):#quando nao for bloqueado    \n",
    "                pos = action[2]\n",
    "                if(l_end==r_end==-1):\n",
    "                    pos = action[2]\n",
    "                    l_end = action[0]\n",
    "                    r_end = action[1]\n",
    "                elif(action[1]==\"left\"):\n",
    "                #substitui uma das pontas pela nova ação\n",
    "                    l_end = action[0]\n",
    "                else:\n",
    "                    r_end = action[0]\n",
    "                #print \"pos: \"+str(pos)\n",
    "                value =hand.pop(pos)\n",
    "            \n",
    "        #featuresValidator = FeaturesValidator()\n",
    "        result = self.featureValidator.validate(result,hand,handOp,action,\n",
    "                                                player,state)\n",
    "        if(action is not None):\n",
    "            if(action[0]!=None):\n",
    "                hand.insert(pos,value)\n",
    "        \n",
    "        return result #funcao principal que processa a feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,player,act):\n",
    "        self.player = player\n",
    "        self.act = act\n",
    "        self.children = []\n",
    "        self.max_child_number = 0\n",
    "        self.know_children_number = 0\n",
    "        self.valueQ = 0.0\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.identifier = 0\n",
    "        self.firstTime = True\n",
    "        self.expanded = False\n",
    "        self.isTerminal = False\n",
    "        self.reward = 0 #recompensa utilizada quando esse for o no terminal\n",
    "    def choosen_act(self,actions):\n",
    "        try:\n",
    "            return actions[self.know_children_number]\n",
    "        except:\n",
    "            print \"Unexpected error:\", sys.exc_info()[1]\n",
    "            print \"error on choosen act, children number:\" + str(self.know_children_number)\n",
    "            print actions\n",
    "            raise NameError('Stopping program')\n",
    "    #funcao atribui um no filho a um nó pai que ainda nao teve todos os filhos explorados\n",
    "    def assign_child(self, identifier,actions):#ele so tera os ids, nao os obj em si\n",
    "        if(self.firstTime):\n",
    "            self.max_child_number = len(actions)\n",
    "            self.firstTime = False\n",
    "        self.know_children_number+=1\n",
    "        self.children.append(identifier)\n",
    "        if(self.know_children_number == self.max_child_number):\n",
    "            self.expanded = True\n",
    "            #print \"expanded\"\n",
    "            #print self.max_child_number\n",
    "    def set_id(self,identifier):\n",
    "        self.identifier = identifier\n",
    "    def add_value(self, value):\n",
    "        self.total+=value/(69.0)#convertendo para intervalo de 0 a 1\n",
    "        self.valueQ=self.total/self.count\n",
    "    def add_count(self):\n",
    "        self.count+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MCST:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.trajectory = []\n",
    "        self.identifier = -1#se lembre sempre de colocar o root\n",
    "    def add_node(self,node):\n",
    "        self.identifier+=1\n",
    "        self.nodes[self.identifier] = node\n",
    "        return self.identifier\n",
    "    def add_trajectory(self,identifier):\n",
    "        self.trajectory.append(identifier)\n",
    "    def resetTrajectory(self):\n",
    "        self.trajectory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UCT:\n",
    "    def __init__(self,c):\n",
    "        self.c = c\n",
    "        self.tree = MCST()\n",
    "        \n",
    "    def treeReset(self,rootNode):\n",
    "        self.tree = MCST()\n",
    "        self.tree.add_node(rootNode)\n",
    "        \n",
    "    def resetTrajectory(self):\n",
    "        self.tree.resetTrajectory()\n",
    "        \n",
    "    def electUCT(self,node,criteria):\n",
    "        elected_id = \"\"\n",
    "        if(criteria == \"Max\"):\n",
    "            maxValueQ = -99999999\n",
    "            for child_id in node.children:\n",
    "                currentVal = self.tree.nodes[child_id].valueQ\n",
    "                if(currentVal>maxValueQ):\n",
    "                    maxValueQ = currentVal\n",
    "                    elected_id = child_id\n",
    "        elif(criteria == \"Robust\"):\n",
    "            maxCount = 0\n",
    "            for child_id in node.children:\n",
    "                currentCount = self.tree.nodes[child_id].count\n",
    "                if(currentCount>maxCount):\n",
    "                    maxCount = currentCount\n",
    "                    elected_id = child_id\n",
    "        return self.tree.nodes[elected_id]\n",
    "            \n",
    "            \n",
    "    def calculateUCT(self,node,fatherNode):\n",
    "        if(fatherNode.count!=0 and node.count!=0):\n",
    "            return node.valueQ + 2*self.c*(math.sqrt(2*math.log(fatherNode.count)/node.count))\n",
    "        else:#na conf atual nunca deveria acontecer\n",
    "            return 9999999#infinidade, para nos nao explorados\n",
    "        \n",
    "    def selectUCT(self,currentNode):\n",
    "        self.tree.add_trajectory(currentNode.identifier)#adicione o root na trajetoria\n",
    "        return self.select(currentNode)\n",
    "    def select(self,currentNode):\n",
    "        if (not currentNode.children or not currentNode.expanded):\n",
    "            return currentNode###########deveria adicionar trajetoria tbm?\n",
    "        #o uct so e aplicado em nos com um numero de visitas T\n",
    "        if(currentNode.count>=T):\n",
    "            maxVal = -99999999 #tomar cuidado\n",
    "            choosenNode = currentNode\n",
    "            for child_id in currentNode.children:\n",
    "                #print \"node:\"+str(node.player)\n",
    "                currentVal = self.calculateUCT(self.tree.nodes[child_id],currentNode)\n",
    "                if(currentVal>maxVal):\n",
    "                    maxVal = currentVal\n",
    "                    choosen_child_id = child_id #aki deve escolher o melhor\n",
    "        else:#escolha com o msm metodo da simulacao\n",
    "            playout_act = control.policyAct(state,currentNode.player)\n",
    "            for child_id in currentNode.children:\n",
    "                if(self.tree.nodes[child_id].act==playout_act):#tem como melhorar?\n",
    "                    choosen_child_id = child_id\n",
    "            \n",
    "        self.tree.add_trajectory(choosen_child_id)\n",
    "        choosenNode= self.select(self.tree.nodes[choosen_child_id])\n",
    "        return choosenNode\n",
    "    \n",
    "    def replay(self,node,state,domino):\n",
    "        history = self.tree.trajectory\n",
    "        if not history:\n",
    "            return state\n",
    "        for h in history:\n",
    "            node = self.tree.nodes[h]\n",
    "            #print \"player \"+str(node.player)+\" replayed \"+str(node.act)\n",
    "            domino.playAction(state,node.act,node.player)\n",
    "            \n",
    "        return state\n",
    "        \n",
    "    def expand(self,node,state,domino):\n",
    "        if not node.isTerminal:    \n",
    "            state = self.replay(node,state,domino)\n",
    "            #a proxima jogada vai ser do oponente\n",
    "            if(node.player == \"rootP1\" or node.player == \"p2\"):\n",
    "                actions = domino.possibleActions(state,\"p1\")\n",
    "                #print \"state: \"+str(state)\n",
    "                choosen_act = node.choosen_act(actions)#pega 1 acao ainda nao explorada\n",
    "                state= domino.playAction(state,choosen_act,\"p1\")\n",
    "            else:\n",
    "                actions = domino.possibleActions(state,\"p2\")\n",
    "                choosen_act = node.choosen_act(actions)\n",
    "                state= domino.playAction(state,choosen_act,\"p2\")\n",
    "            #com mais jogadores teria tambem que respeitar a ordem sempre\n",
    "            if(node.player == \"p2\" or node.player == \"rootP1\"):\n",
    "                new_node = Node(\"p1\",choosen_act)\n",
    "            else:\n",
    "                new_node = Node(\"p2\",choosen_act)\n",
    "            new_id = self.tree.add_node(new_node)\n",
    "            new_node.set_id(new_id)\n",
    "            node.assign_child(new_id,actions)\n",
    "            self.tree.add_trajectory(new_id)#para backpropagation\n",
    "            if(state[0]>=3):\n",
    "                new_node.isTerminal = True\n",
    "                rootNode = self.tree.nodes[0]\n",
    "                if(rootNode.player == \"rootP1\"):# a recompensa ficara gravada no ultimo\n",
    "                    new_node.reward = domino.reward(state,\"p1\")#no para evitar recalculo\n",
    "                else:\n",
    "                    new_node.reward = domino.reward(state,\"p2\")\n",
    "            return new_node\n",
    "        else:\n",
    "            return node\n",
    "    \n",
    "    def playoutRL(self,lastNode,state,domino,control):\n",
    "        if lastNode.isTerminal:\n",
    "            return lastNode.reward\n",
    "        if(lastNode.player==\"p1\"):\n",
    "            player = \"p2\"\n",
    "        else:\n",
    "            player = \"p1\"\n",
    "        act = control.policyAct(state,player)\n",
    "        #print \"Playout: \"\n",
    "        while(state[0]<3):\n",
    "            state = domino.playAction(state,act,player)\n",
    "            #print \"   \"+ player + \" played \"+str(act)\n",
    "            if(player==\"p1\"):\n",
    "                player = \"p2\"\n",
    "            else:\n",
    "                player = \"p1\"\n",
    "            act = control.policyAct(state,player)\n",
    "        #sempre retorne a recompensa q o p1 ganha, lembrando de ativar a punicao,\n",
    "        #para que o retorno nao seja sempre 0(quando perder), mas sim a qtd negativa\n",
    "        #de pontos ganhos pelo oponente\n",
    "        rootNode = self.tree.nodes[0]\n",
    "        if(rootNode.player == \"rootP1\"):\n",
    "            return domino.reward(state,\"p1\")\n",
    "        else:\n",
    "            return domino.reward(state,\"p2\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def backpropagate(self,reward):\n",
    "        history = self.tree.trajectory#se lembrar de tirar self.tree do global\n",
    "        for h in history:\n",
    "            node = self.tree.nodes[h]\n",
    "            node.add_count()\n",
    "            node.add_value(reward)\n",
    "            \n",
    "        \n",
    "        self.tree.resetTrajectory()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     24,
     28,
     33,
     52,
     84,
     94,
     104,
     122,
     149,
     166,
     180,
     188
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Controlador para utilizar e treinar rede Neural(Features)\n",
    "class Control:\n",
    "    def __init__(self,e,features,domino,gamma,tdLambda,uct):\n",
    "        self.features = features\n",
    "        self.featuresVector = np.zeros(1)\n",
    "        self.e = e\n",
    "        self.domino = domino\n",
    "        self.tdLambda = tdLambda\n",
    "        self.eTraces = np.zeros(features.getFeaturesWeights().size)\n",
    "        self.gamma = gamma\n",
    "        self.uct = uct\n",
    "        \n",
    "        \n",
    "    \n",
    "    def getFeatures(self):\n",
    "        return self.features\n",
    "    \n",
    "    def setFeatures(self,features):\n",
    "        self.features = features\n",
    "        \n",
    "   \n",
    "    def fillTraces(self):\n",
    "        self.eTraces[self.featuresVector>0] +=1\n",
    "    \n",
    "    def generateVector(self,state,act,player):\n",
    "        self.featuresVector = self.features.atomicFeatures(state,act,player)\n",
    "        \n",
    "   \n",
    "    def qValue(self,state,act,player):\n",
    "        featureVals = self.features.atomicFeatures(state,act,player)\n",
    "        val = np.dot(self.features.getFeaturesWeights(), featureVals)    \n",
    "        return val\n",
    "\n",
    "    def eGreedyPicker(self,actions,state,player):\n",
    "        rand = np.random.random_sample()\n",
    "        bestValue = 0 #tomar cuidado aqui\n",
    "        cond = False\n",
    "        if(rand > self.e):\n",
    "            for act in actions:  \n",
    "                value = self.qValue(state,act,player)\n",
    "                if(not cond):\n",
    "                    bestValue = value\n",
    "                    choosenAct = act\n",
    "                    cond = True\n",
    "                if(value> bestValue):\n",
    "                    bestValue = value\n",
    "                    choosenAct = act\n",
    "        else:\n",
    "            choosenAct = random.choice(actions)\n",
    "\n",
    "        return choosenAct\n",
    "    \n",
    "    def minmaxPicker(self,actions,state,player):\n",
    "        rand = np.random.random_sample()\n",
    "        index_choosenAct=0\n",
    "        i= 0\n",
    "        maxOpValue = -999999999\n",
    "        simulation_state = copy.deepcopy(state)\n",
    "        if(player == \"p1\"):\n",
    "            opPlayer = \"p2\"\n",
    "        else:\n",
    "            opPlayer = \"p1\"\n",
    "        if(rand > self.e):\n",
    "            for act in actions:  \n",
    "                value = self.qValue(simulation_state,act,player)\n",
    "                #if(value == 0):\n",
    "                    #return random.choice(actions)\n",
    "                simulation_state = dominoes.playAction(simulation_state,act,player)\n",
    "                opActions = dominoes.possibleActions(simulation_state,opPlayer)\n",
    "                for opAct in opActions:\n",
    "                    opValue = self.qValue(simulation_state,opAct,opPlayer)\n",
    "                    if(opValue == 0):\n",
    "                        return random.choice(actions)\n",
    "                    if(opValue>maxOpValue):\n",
    "                        maxOpValue = opValue\n",
    "                        index_choosenAct = i\n",
    "\n",
    "                simulation_state = copy.deepcopy(state)\n",
    "                i+=1\n",
    "            return actions[index_choosenAct]\n",
    "        else:\n",
    "            choosenAct = random.choice(actions)\n",
    "            return choosenAct\n",
    "\n",
    "    def policyAct(self,state,player):\n",
    "        actions = self.domino.possibleActions(state,player)\n",
    "        #escolhe a partir dos valores na q-value com tecnica e-greedy\n",
    "        if(actions[0] is None):\n",
    "            return actions\n",
    "        else:\n",
    "            choosenAct = self.eGreedyPicker(actions,state,player)\n",
    "\n",
    "        return choosenAct\n",
    "    \n",
    "    def minmaxAct(self,state,player):\n",
    "        actions = self.domino.possibleActions(state,player)\n",
    "        if(actions[0] is None):\n",
    "            return actions\n",
    "        else:\n",
    "            choosenAct = self.minmaxPicker(actions,state,player)\n",
    "\n",
    "        return choosenAct\n",
    "    \n",
    "    #deveria ser mcstSearch\n",
    "    def mcstAct(self,state,player,N):\n",
    "        if(player == \"p1\"):\n",
    "            rootNode = Node(\"rootP1\",None)\n",
    "        else:\n",
    "            rootNode = Node(\"rootP2\",None)\n",
    "        self.uct.treeReset(rootNode)\n",
    "        \n",
    "        for i in range(N):\n",
    "            new_state = copy.deepcopy(state)\n",
    "            selected_node = self.uct.selectUCT(rootNode)\n",
    "            new_node = self.uct.expand(selected_node,new_state,dominoes)\n",
    "            r = self.uct.playoutRL(new_node,new_state,dominoes,self)\n",
    "            self.uct.backpropagate(r)\n",
    "            uct.resetTrajectory() #praq?\n",
    "            elect_node = self.uct.electUCT(rootNode,\"Max\")\n",
    "            #print elect_node.act\n",
    "        return elect_node.act \n",
    "    \n",
    "    def pimcSearch(self,state,player,mcstN,pimcN):\n",
    "        actions = dominoes.possibleActions(state,player)\n",
    "        #print \"Actions: \"+str(actions)\n",
    "        actionsValues = {}\n",
    "        maxAct = ''\n",
    "        for i in range(len(actions)):\n",
    "            actionsValues[i] = 0\n",
    "         \n",
    "        \n",
    "        for i in range(pimcN):\n",
    "            op_hand = self.Sample(state,player)\n",
    "            #print \"Sampled hand:\" +str(op_hand)\n",
    "            node = self.PerfInfoValue(state,op_hand,player,mcstN)\n",
    "            #print \"Choosen node: \"+str(node.act)+ \" id: \"+str(node.identifier)\n",
    "            #identifier e a propria pos na lista de acoes possiveis\n",
    "            actionsValues[int(node.identifier)-1] += node.valueQ #corrige pos com -1\n",
    "            #print \"Search returned value: \"+str(node.valueQ)\n",
    "            #print \"has now value: \"+str(actionsValues[int(node.identifier)-1])\n",
    "        argmax  = actionsValues[0]\n",
    "        maxAct = 0\n",
    "        for act_index in actionsValues:\n",
    "            if(actionsValues[act_index]>argmax):\n",
    "                argmax = actionsValues[act_index]\n",
    "                maxAct = act_index\n",
    "        #print \"Best Action is \"+str(actions[maxAct] )+\" with value: \"+str(argmax)\n",
    "        return actions[maxAct]   \n",
    "    \n",
    "    def Sample(self,state,player):\n",
    "        if(player==\"p1\"):\n",
    "            op_hand = state[2]\n",
    "        else:\n",
    "            op_hand = state[1]\n",
    "        info_set = op_hand+state[8]\n",
    "        generated_op_hand = []\n",
    "        \n",
    "        for i in range(len(op_hand)):\n",
    "            random_index = randrange(0,len(info_set))\n",
    "            generated_op_hand.append(info_set[random_index])\n",
    "            del info_set[random_index]\n",
    "        return generated_op_hand\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def PerfInfoValue(self,state,op_hand,player,N):\n",
    "        if(player == \"p1\"):\n",
    "            backup = state[2] #mao real e guardada\n",
    "            state[2] = op_hand # substituida pela mao gerada aleatoriamente\n",
    "        else:\n",
    "            backup = state[1] \n",
    "            state[1] = op_hand\n",
    "        node = self.mcstAct(state,player,N) #busca no estado ja conhecido-perfeita informacao\n",
    "        if(player == \"p1\"):\n",
    "            state[2] = backup #retorna a imperfeita informacao\n",
    "        else:\n",
    "            state[1] = backup\n",
    "        return node\n",
    "    \n",
    "    def alpha(self,vector):#calcua taxa de aprendizado de acordo com quantidade de features atuais\n",
    "        \n",
    "        unique, counts = np.unique(vector, return_counts=True)\n",
    "        if((counts[0])==self.featuresVector.size):\n",
    "            return 0.01\n",
    "        a = 0.01/(counts[1]) #constante por numero total de 1\n",
    "        return a\n",
    "    \n",
    "    def decayTraces(self):\n",
    "        if(self.tdLambda>0):\n",
    "            feat = self.featuresVector\n",
    "            self.eTraces[feat>0]=self.eTraces[feat>0]*self.gamma*self.tdLambda\n",
    "            self.auxFeaturesVector = self.eTraces\n",
    "            self.auxFeaturesVector[self.featuresVector==0] = 0#retorna trace das carac atuais\n",
    "            return self.auxFeaturesVector \n",
    "        else:\n",
    "            return self.featuresVector\n",
    "        \n",
    "    \n",
    "    def evaluate(self,state,val,act,player,actType):\n",
    "        self.fillTraces()\n",
    "        r = dominoes.reward(state,player)\n",
    "        if(actType==\"mcst\"):\n",
    "            next_action = self.mcstAct(state,player,20)\n",
    "        elif(actType==\"minmax\"):\n",
    "            next_action = self.minmaxAct(state,player)\n",
    "        else:\n",
    "            next_action = self.policyAct(state,player)\n",
    "        new_value = self.qValue(state,next_action,player)\n",
    "        target = r+ self.gamma * new_value        # gamma = 0.9\n",
    "        delta = target - val # prediction error\n",
    "        featureWeights = self.features.getFeaturesWeights()\n",
    "        featureWeights += self.alpha(self.featuresVector) * delta *self.decayTraces()\n",
    "        self.features.setFeaturesWeights(featureWeights)\n",
    "    \n",
    "        elements = [state,new_value,next_action,r]\n",
    "        return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Complexity test2 on number of actions\n",
    "def minimaxAct(state,player):\n",
    "    copy_state = copy.deepcopy(state)\n",
    "    count = 0\n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    #print actions\n",
    "    for act in actions:\n",
    "        count+=1\n",
    "        copy_state = copy.deepcopy(state)\n",
    "        count = minmax(copy_state,act,\"p1\",count)\n",
    "    print count\n",
    "    \n",
    "def minmax(state,act,player,count):\n",
    "    #print \"Playing: \"+str(act)\n",
    "    state = dominoes.playAction(state,act,player)\n",
    "    if(state[0]==3):\n",
    "        return count\n",
    "    if(player == \"p1\"):\n",
    "        player = \"p2\"\n",
    "    else:\n",
    "        player = \"p1\"   \n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    #print \"possibel actions: \"+str(actions)\n",
    "    for act in actions:\n",
    "        count+=1\n",
    "        copy_state = copy.deepcopy(state)\n",
    "        count = minmax(copy_state,act,player,count)\n",
    "    return count\n",
    "        \n",
    "dominoes = Domino(0,0,0,0,True,\"Draw\")\n",
    "state = [1,[(2,4),(3,5),(1,1),(1,4),(0,4),(1,2),(4,4)],\n",
    "         [(3,0),(1,6),(1,3),(3,4),(5,4),(2,2),(3,6)],\n",
    "         [],-1,-1,False,False,[(6,6),(4,6),(3,3),(2,0),(2,3),(2,5),(2,6)]]\n",
    "\n",
    "minimaxAct(state,\"p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting weight1: [ -3.06871536e-02   9.31693139e-02  -2.96977463e-01  -2.80706560e-01\n",
      "  -6.50085005e-01  -7.42498397e-01  -8.41546793e-01  -1.24227221e+00\n",
      "   5.71065832e-02   5.73049591e+00  -6.52594498e-01  -2.29576140e+00\n",
      "  -1.84812975e+00  -5.13398712e-01   1.54015280e-02  -5.91819533e+00\n",
      "  -7.79631883e-01   1.97342521e+00   2.51374566e+00   2.02581787e+00\n",
      "   1.54015280e-02   1.68898790e-02   8.05816643e-02  -3.06871536e-02\n",
      "   9.29742602e-02   1.01278338e-01   9.78386536e-02   3.21303015e-02\n",
      "  -1.84235676e-03   1.44321036e-01  -3.06871536e-02   9.29742602e-02\n",
      "   1.01278338e-01   9.78386536e-02   3.21303015e-02  -1.84235676e-03\n",
      "   1.44321036e-01   1.46190890e-01   6.76643458e-02   5.45341435e-01\n",
      "  -3.09820555e-02   7.00336843e-01   7.47166833e-01   7.48741214e-01\n",
      "   6.96895165e-01   4.09275740e-01   2.54004017e-02  -1.05418139e+00\n",
      "  -1.56573045e+00  -1.00010589e+00   0.00000000e+00   7.97727961e-01\n",
      "  -3.71157352e-02  -2.51051205e-01  -6.96080530e-02  -3.93988860e-03\n",
      "   0.00000000e+00   0.00000000e+00   2.59592278e+00   4.12528123e-01\n",
      "  -3.09745414e-01  -1.06226767e+00  -1.00134841e+00  -1.78289785e-01\n",
      "  -2.07865393e-02   2.07449448e+00   6.64251153e-01  -9.07304798e-01\n",
      "  -1.25613761e+00  -1.63543669e-01   2.42535231e-02   0.00000000e+00\n",
      "   2.08913234e+00  -9.59581973e-02  -1.41403774e+00  -1.17988803e-01\n",
      "  -2.51345203e-02   0.00000000e+00   0.00000000e+00  -6.69390821e-01\n",
      "  -1.68508721e-01   7.61770028e-01   4.92595965e-01   1.95466281e-02\n",
      "   0.00000000e+00   0.00000000e+00  -1.89905935e+00  -5.98121571e-01\n",
      "  -2.66362997e-01   6.76451999e-01   1.16102751e+00   1.09684370e+00\n",
      "   2.52563749e-01  -1.79157340e+00  -1.22936708e+00   3.54150406e-01\n",
      "   1.46708225e+00   1.39110893e+00   2.28817290e-01   1.57946933e-02\n",
      "  -2.01005245e+00  -3.93718054e-01   1.23243865e+00   1.56173606e+00\n",
      "   4.56088705e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "P1victories: 4039 P1 Accumulated reward: -30956\n",
      "P2victories: 5961 P2 Accumulated reward: 30956\n"
     ]
    }
   ],
   "source": [
    "#Training1 : Treinar extensive network\n",
    "dominoes = Domino(0,0,0,0,True,\"Block\")#\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "featureWeights1 = np.zeros(110)#630 comb 37820 comb2\n",
    "featureWeights2  = np.zeros(110)\n",
    "\n",
    "network1 = ExtensiveNetwork()\n",
    "network2 = ExtensiveNetwork()\n",
    "features1 = Features(featureWeights1,network1)\n",
    "features2 = Features(featureWeights2,network2)\n",
    "uct = UCT(0.1)\n",
    "T = 0 \n",
    "controlP1 = Control(0.03,features1,dominoes,0.4,0,uct)\n",
    "controlP2 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "\n",
    "r = 0\n",
    "\n",
    "duration = 0\n",
    "#self-play\n",
    "firstplay = 0\n",
    "accumulatedRewardP1 = 0\n",
    "accumulatedRewardP2 = 0\n",
    "P1Wins = 0\n",
    "P2Wins = 0\n",
    "\n",
    "#para medir tempo\n",
    "#start_time = timeit.default_timer()\n",
    "#print(timeit.default_timer() - start_time)\n",
    "for i in range(0,10000):\n",
    "    flag = True\n",
    "    state = dominoes.startGame()\n",
    "\n",
    "    actP1 = controlP1.minmaxAct(state,\"p1\")\n",
    "    val1 = controlP1.qValue(state,actP1,\"p1\")\n",
    "    actP2 = controlP2.policyAct(state,\"p2\")\n",
    "    val2 = controlP2.qValue(state,actP2,\"p2\")\n",
    "    controlP2.generateVector(state,actP2,\"p2\")\n",
    "    while(dominoes.termination(state) == False):\n",
    "        \n",
    "        controlP1.generateVector(state,actP1,\"p1\") \n",
    "        state = dominoes.playAction(state, actP1,\"p1\")\n",
    "        state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"default\")\n",
    "        \n",
    "        if(state[0]>=3):\n",
    "            flag = False\n",
    "        controlP2.generateVector(state,actP2,\"p2\")\n",
    "        accumulatedRewardP2+=r\n",
    "        state = dominoes.playAction(state, actP2,\"p2\")\n",
    "        state,val1,actP1,r =controlP1.evaluate(state,val1,actP1,\"p1\",\"minmax\")\n",
    "        accumulatedRewardP1 +=r\n",
    "        if(dominoes.termination(state) == True):\n",
    "            if(flag):\n",
    "                state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"default\")\n",
    "                accumulatedRewardP2+=r\n",
    "            if(state[0]==4):\n",
    "                P1Wins+=1\n",
    "            else:\n",
    "                P2Wins+=1\n",
    "        \n",
    "featureWeights1 = controlP1.getFeatures().getFeaturesWeights()\n",
    "featureWeights2 = controlP2.getFeatures().getFeaturesWeights()\n",
    "\n",
    "print \"Resulting weight1: \"+str(featureWeights1)\n",
    "#print \"Resulting weight2: \"+str(featureWeights2)\n",
    "print \"P1victories: \"+str(P1Wins) + \" P1 Accumulated reward: \"+ str(accumulatedRewardP1)\n",
    "print \"P2victories: \"+str(P2Wins) + \" P2 Accumulated reward: \"+ str(accumulatedRewardP2)\n",
    "if(P1Wins>P2Wins):\n",
    "    winnerWeigth = featureWeights1\n",
    "else:\n",
    "    winnerWeigth = featureWeights2\n",
    "np.save('ExtensiveNetMinMax', winnerWeigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Automatic Training1 : Treinar extensive network\n",
    "for l in range (0,11):\n",
    "    dominoes = Domino(0,0,0,0,True,\"Block\")#\n",
    "    e = 0.09  # epsilon-greedy proportion\n",
    "    featureWeights1 = np.zeros(110)#630 comb 37820 comb2\n",
    "    featureWeights2 = np.zeros(110)\n",
    "    network1 = ExtensiveNetwork2()\n",
    "    network2 = ExtensiveNetwork2()\n",
    "    features1 = Features(featureWeights1,network1)\n",
    "    features2 = Features(featureWeights2,network2)\n",
    "    uct = UCT(0.1)\n",
    "    T = 0 \n",
    "    controlP2 = Control(0.03,features1,dominoes,0.4,l/10,uct)\n",
    "    controlP1 = Control(0.03,features2,dominoes,0.4,l/10,uct)\n",
    "    r = 0\n",
    "\n",
    "    duration = 0\n",
    "    #self-play\n",
    "    firstplay = 0\n",
    "    accumulatedRewardP1 = 0\n",
    "    accumulatedRewardP2 = 0\n",
    "    P1Wins = 0\n",
    "    P2Wins = 0\n",
    "\n",
    "\n",
    "    for i in range(0,1000):\n",
    "        flag = True\n",
    "        state = dominoes.startGame()\n",
    "\n",
    "        actP1 = controlP1.policyAct(state,\"p1\")\n",
    "        val1 = controlP1.qValue(state,actP1,\"p1\")\n",
    "        actP2 = controlP2.policyAct(state,\"p2\")\n",
    "        val2 = controlP2.qValue(state,actP2,\"p2\")\n",
    "        controlP2.generateVector(state,actP2,\"p2\")\n",
    "        while(dominoes.termination(state) == False):\n",
    "\n",
    "            controlP1.generateVector(state,actP1,\"p1\") \n",
    "            state = dominoes.playAction(state, actP1,\"p1\")\n",
    "            state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"default\")\n",
    "\n",
    "            if(state[0]>=3):\n",
    "                flag = False\n",
    "            controlP2.generateVector(state,actP2,\"p2\")\n",
    "            accumulatedRewardP2+=r\n",
    "            state = dominoes.playAction(state, actP2,\"p2\")\n",
    "            state,val1,actP1,r =controlP1.evaluate(state,val1,actP1,\"p1\",\"default\")\n",
    "            accumulatedRewardP1 +=r\n",
    "            if(dominoes.termination(state) == True):\n",
    "                if(flag):\n",
    "                    state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"default\")\n",
    "                    accumulatedRewardP2+=r\n",
    "                if(state[0]==4):\n",
    "                    P1Wins+=1\n",
    "                else:\n",
    "                    P2Wins+=1\n",
    "\n",
    "    featureWeights1 = controlP1.getFeatures().getFeaturesWeights()\n",
    "    featureWeights2 = controlP2.getFeatures().getFeaturesWeights()\n",
    "\n",
    "    print \"Resulting weight1: \"+str(featureWeights1)\n",
    "    #print \"Resulting weight2: \"+str(featureWeights2)\n",
    "    print \"P1victories: \"+str(P1Wins) + \" P1 Accumulated reward: \"+ str(accumulatedRewardP1)\n",
    "    print \"P2victories: \"+str(P2Wins) + \" P2 Accumulated reward: \"+ str(accumulatedRewardP2)\n",
    "    if(P1Wins>P2Wins):\n",
    "        winnerWeigth = featureWeights1\n",
    "    else:\n",
    "        winnerWeigth = featureWeights2\n",
    "    name = \"Training\"+str(l)\n",
    "    np.save(name, winnerWeigth)\n",
    "    print \"Trained weigth: \"+str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TD Leaf Training\n",
    "dominoes = Domino(0,0,0,0,True,\"Block\")#winReward,lostReward,blockingReward,blockedReward,lostPunition\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "featureWeights1 = np.zeros(300)\n",
    "featureWeights2 = np.zeros(300)\n",
    "featureWeights3 = np.load('neuralNetP1.npy')\n",
    "extNetwork = ExtensiveNetwork()\n",
    "network= Network()\n",
    "features1 = Features(featureWeights1,extNetwork)\n",
    "features2 = Features(featureWeights2,extNetwork)\n",
    "features3 = Features(featureWeights3,network)\n",
    "uct = UCT(0.1)\n",
    "T = 0 \n",
    "controlP1 = Control(0.03,features1,dominoes,0.4,0,uct)\n",
    "controlP2 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "r = 0\n",
    "\n",
    "duration = 0\n",
    "#self-play\n",
    "firstplay = 0\n",
    "accumulatedRewardP1 = 0\n",
    "accumulatedRewardP2 = 0\n",
    "P1Wins = 0\n",
    "P2Wins = 0\n",
    "\n",
    "for i in range(0,1000):\n",
    "    flag = True\n",
    "    state = dominoes.startGame()\n",
    "    controlP1.setFeatures(features3)\n",
    "    controlP2.setFeatures(features3)\n",
    "    actP1 = controlP1.mcstAct(state,\"p1\",20)\n",
    "    val1 = controlP1.qValue(state,actP1,\"p1\")\n",
    "    actP2 = controlP2.mcstAct(state,\"p2\",20)\n",
    "    val2 = controlP2.qValue(state,actP2,\"p2\")\n",
    "    controlP1.setFeatures(features1)\n",
    "    controlP2.setFeatures(features2)\n",
    "    controlP2.generateVector(state,actP2,\"p2\")\n",
    "    while(dominoes.termination(state) == False):\n",
    "        \n",
    "        controlP1.generateVector(state,actP1,\"p1\")\n",
    "        state = dominoes.playAction(state, actP1,\"p1\")\n",
    "        state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"TdLeaf\",features3)\n",
    "        if(state[0]>=3):\n",
    "            flag = False\n",
    "        controlP2.generateVector(state,actP2,\"p2\")\n",
    "        accumulatedRewardP2+=r\n",
    "        state = dominoes.playAction(state, actP2,\"p2\")\n",
    "        state,val1,actP1,r =controlP1.evaluate(state,val1,actP1,\"p1\",\"TdLeaf\",features3)\n",
    "        accumulatedRewardP1 +=r\n",
    "        \n",
    "        if(dominoes.termination(state) == True):\n",
    "            if(flag):\n",
    "                state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\",\"TdLeaf\",features3)\n",
    "                accumulatedRewardP2+=r\n",
    "            if(state[0]==4):\n",
    "                P1Wins+=1\n",
    "            else:\n",
    "                P2Wins+=1\n",
    "        \n",
    "featureWeights1 = controlP1.getFeatures().getFeaturesWeights()\n",
    "featureWeights2 = controlP2.getFeatures().getFeaturesWeights()\n",
    "\n",
    "print \"Resulting weight1: \"+str(featureWeights1)\n",
    "#print \"Resulting weight2: \"+str(featureWeights2)\n",
    "print \"P1victories: \"+str(P1Wins) + \" P1 Accumulated reward: \"+ str(accumulatedRewardP1)\n",
    "print \"P2victories: \"+str(P2Wins) + \" P2 Accumulated reward: \"+ str(accumulatedRewardP2)\n",
    "if(P1Wins>P2Wins):\n",
    "    winnerWeigth = featureWeights1\n",
    "else:\n",
    "    winnerWeigth = featureWeights2\n",
    "np.save('ExtensiveNetTDLeaf', winnerWeigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training2 : Treinar so como 1 jogador e o suficiente para cobrir todos os casos importantes\n",
    "dominoes = Domino(0,0,0,0,True,\"Block\")#winReward,lostReward,blockingReward,blockedReward,lostPunition\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "featureWeights1 = np.zeros(35)#630 comb 37820 comb2\n",
    "featureWeights2 = np.load('neuralNetP1.npy')\n",
    "network1 = Network()\n",
    "network2 = Network()\n",
    "features1 = Features(featureWeights1,network1)\n",
    "features2 = Features(featureWeights2,network2)\n",
    "uct = UCT(0.1)\n",
    "T = 0 trol(0.03,features1,dominoes,0.4,0,uct)\n",
    "controlP2 = C\n",
    "controlP1 = Conontrol(0.03,features2,dominoes,0.4,0,uct)\n",
    "r = 0\n",
    "\n",
    "duration = 0\n",
    "#self-play\n",
    "firstplay = 0\n",
    "accumulatedRewardP1 = 0\n",
    "accumulatedRewardP2 = 0\n",
    "P1Wins = 0\n",
    "P2Wins = 0\n",
    "\n",
    "for i in range(0,1000):\n",
    "    flag = True\n",
    "    state = dominoes.startGame()\n",
    "    actP1 = controlP1.mcstAct(state,\"p1\",20)\n",
    "    val1 = controlP1.qValue(state,actP1,\"p1\")\n",
    "    actP2 = controlP2.mcstAct(state,\"p2\",20)\n",
    "    val2 = controlP2.qValue(state,actP2,\"p2\")\n",
    "    controlP2.generateVector(state,actP2,\"p2\")\n",
    "    while(dominoes.termination(state) == False):\n",
    "        \n",
    "        controlP1.generateVector(state,actP1,\"p1\")\n",
    "        state = dominoes.playGame(state, actP1,\"p1\")\n",
    "        state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\")\n",
    "        if(state[0]>=3):\n",
    "            flag = False\n",
    "        controlP2.generateVector(state,actP2,\"p2\")\n",
    "        accumulatedRewardP2+=r\n",
    "        state = dominoes.playGame(state, actP2,\"p2\")\n",
    "        state,val1,actP1,r =controlP1.evaluate(state,val1,actP1,\"p1\")\n",
    "        accumulatedRewardP1 +=r\n",
    "        \n",
    "        if(dominoes.termination(state) == True):\n",
    "            if(flag):\n",
    "                state,val2,actP2,r =controlP2.evaluate(state,val2,actP2,\"p2\")\n",
    "                accumulatedRewardP2+=r\n",
    "            if(state[0]==4):\n",
    "                P1Wins+=1\n",
    "            else:\n",
    "                P2Wins+=1\n",
    "        \n",
    "featureWeights1 = controlP1.getFeatures().getFeaturesWeights()\n",
    "featureWeights2 = controlP2.getFeatures().getFeaturesWeights()\n",
    "\n",
    "print \"Resulting weight1: \"+str(featureWeights1)\n",
    "#print \"Resulting weight2: \"+str(featureWeights2)\n",
    "print \"P1victories: \"+str(P1Wins) + \" P1 Accumulated reward: \"+ str(accumulatedRewardP1)\n",
    "print \"P2victories: \"+str(P2Wins) + \" P2 Accumulated reward: \"+ str(accumulatedRewardP2)\n",
    "if(P1Wins>P2Wins):\n",
    "    winnerWeigth = featureWeights1\n",
    "else:\n",
    "    winnerWeigth = featureWeights2\n",
    "np.save('MCST_neuralNetP1', winnerWeigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initial2\n",
    "dominoes = Domino(0,0,0,0,True)#tem que saber diferenciar um outcome ruim pra um 0\n",
    "state = dominoes.startGame()\n",
    "uct = UCT(0.1)\n",
    "state = [1,[(3,0),(1,6),(1,3)],[(2,4),(3,5),(1,1)],[],-1,-1,False,False,\n",
    "        [(0,0),(2,3),(4,4)]]\n",
    "e = 0.000001\n",
    "T = 0 #threshold, num de visitas necessarios para se aplicar o uct na selecao\n",
    "featureWeights1 = np.load('neuralNetP1.npy')\n",
    "featureWeights2 = np.load('neuralNetP1.npy')\n",
    "network1 = Network()\n",
    "network2 = Network()\n",
    "features1 = Features(featureWeights1,network1)\n",
    "features2 = Features(featureWeights2,network2)\n",
    "controlP1 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "controlP2 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "tree = MCST()\n",
    "player = \"rootP1\"\n",
    "rootNode = Node(player,None)#sempre sera um no fantasma para as acoes possiveis\n",
    "new_state = copy.deepcopy(state)\n",
    "tree.add_node(rootNode)#nunca se esqueca de adicionar o root na arvore antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player1 winnings: 651 Player2 winnings: 349\n",
      "Player1 rewards: 4075 Player2 rewards: -4075\n"
     ]
    }
   ],
   "source": [
    "#IA vs IA\n",
    "dominoes = Domino(0,0,0,0,True,\"Block\")#\n",
    "e = 0.000001  # aqui n ha aprendizagem\n",
    "r = 0\n",
    "duration = 0\n",
    "P1Wins = 0\n",
    "P2Wins = 0\n",
    "firstplay =1\n",
    "accumulatedRewardP1 = 0\n",
    "accumulatedRewardP2 = 0\n",
    "count = 0\n",
    "featureWeights1 = np.load('ExtensiveNetDefault.npy')\n",
    "featureWeights2 = np.load('ExtensiveNetMinMax.npy')\n",
    "network1 = ExtensiveNetwork()\n",
    "network2 = ExtensiveNetwork()\n",
    "features1 = Features(featureWeights1,network1)\n",
    "features2 = Features(featureWeights2,network2)\n",
    "uct = UCT(0.1)\n",
    "T = 0 \n",
    "controlP1 = Control(0.03,features1,dominoes,0.4,0,uct)\n",
    "controlP2 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "r = 0\n",
    "for i in range(0,1000):\n",
    "    \n",
    "    state = dominoes.startGame()\n",
    "    firstplay = random.randint(0,1)\n",
    "    #firstplay = 1\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):\n",
    "            \n",
    "            actP1 = controlP1.policyAct(state,\"p1\")\n",
    "            dominoes.playAction(state, actP1,\"p1\")\n",
    "            actP2 = controlP2.minmaxAct(state,\"p2\")\n",
    "            dominoes.playAction(state, actP2,\"p2\")\n",
    "        else:\n",
    "            actP2 = controlP2.minmaxAct(state,\"p2\")\n",
    "            dominoes.playAction(state, actP2,\"p2\")\n",
    "            actP1 = controlP1.policyAct(state,\"p1\")\n",
    "            dominoes.playAction(state, actP1,\"p1\")\n",
    "        accumulatedRewardP1 += dominoes.reward(state,\"p1\")\n",
    "        accumulatedRewardP2 +=dominoes.reward(state,\"p2\")\n",
    "    if(state[0]==4):\n",
    "        P1Wins+=1\n",
    "    else:\n",
    "        P2Wins+=1\n",
    "print \"Player1 winnings: \"+str(P1Wins) + \" Player2 winnings: \"+str(P2Wins)\n",
    "print \"Player1 rewards: \"+str(accumulatedRewardP1)+\" Player2 rewards: \"+str(accumulatedRewardP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IA vs Other\n",
    "\n",
    "def takeout(state,takeout_piece):\n",
    "    i = 0\n",
    "    for bone in state[8]:\n",
    "        #print \"bone: \"+str(bone) + \" takeout: \"+str(takeout_piece)\n",
    "        if(bone==takeout_piece):\n",
    "            del state[8][i]\n",
    "        i+=1\n",
    "    return state\n",
    "\n",
    "def takeoutHand(state,takeout_piece):\n",
    "    cond = False\n",
    "    i = 0\n",
    "    for bone in state[2]:\n",
    "        if(bone==takeout_piece):\n",
    "            print \"Deleted bone: \"+str(bone)\n",
    "            del state[8][i]\n",
    "            cond = True\n",
    "        i+=1\n",
    "    return [state,cond]\n",
    "      \n",
    "    \n",
    "def iaPlay(state,player):\n",
    "    print(\"inform what side(left/right) the piece has matched or None \")\n",
    "    side = raw_input(\"\")\n",
    "    if(side == \"None\"):\n",
    "        dominoes.playGame(state, None,player)\n",
    "        return\n",
    "    print \"Inform Left and Right:\"\n",
    "    bone = input(\"\")\n",
    "    state = takeout(state,bone)\n",
    "    state,cond = takeoutHand(state,bone)\n",
    "    state[2].insert(0,bone)#coloca para se ter a acao\n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    if(len(actions)>1 and actions[1][1]==side):# no caso de ter 2 acoes da msm peca\n",
    "        dominoes.playGame(state, actions[1],player)\n",
    "    else:#caso 1 so acao ou caso da 1 rodada(valor,valor,index)\n",
    "        dominoes.playGame(state, actions[0],player)\n",
    "    del state[2][0] #retira\n",
    "    if(not cond): \n",
    "        if(len(state[2])>0):\n",
    "            played_piece = state[2][0] # retira-se uma peca da mao do op para equilibrar\n",
    "            del state[2][0]\n",
    "            state[8].insert(0,played_piece)\n",
    "        \n",
    "    print \"Sides after p1 play: \"+str(state[4]) + \",\"+str(state[5])\n",
    "     \n",
    "        \n",
    "cr1 = 0\n",
    "r1 = 0\n",
    "cr2 = 0\n",
    "r2 = 0\n",
    "duration = 0\n",
    "count = 0\n",
    "P1Wins = 0\n",
    "firstplay = 1\n",
    "count+=1\n",
    "r1 = 0\n",
    "r2 = 0\n",
    "state = dominoes.startGame()\n",
    "#firstplay = random.randint(0,1)\n",
    "firstplay = 0\n",
    "while(dominoes.termination(state) == False):\n",
    "    state[1] = []\n",
    "    state[2] = []\n",
    "    op_hand = []\n",
    "    state[8] = []\n",
    "    state[8] = [(x,y) for x in range(7) for y in range(x,7)]\n",
    "    print \"Inform my hand\"\n",
    "    for i in range(7):\n",
    "        print \"Piece\"+str(i)\n",
    "        print \"Inform Left and Right:\"\n",
    "        bone = input(\"\")\n",
    "        state[1].append(bone)\n",
    "        state = takeout(state,bone)\n",
    "        \n",
    "    print \"state now: \"+str(state)    \n",
    "    boneyard = state[8] \n",
    "    op_hand,boneyard = dominoes.buy(op_hand, 7, boneyard)\n",
    "    state[2] = op_hand\n",
    "    state[8] = boneyard\n",
    "    print state\n",
    "    if(firstplay==0):\n",
    "        iaPlay(state,\"p2\")\n",
    "        print \"my hand: \"+str(state[2])\n",
    "        actP1 = controlP1.pimcSearch(state,\"p1\",20,100)\n",
    "        dominoes.playGame(state, actions[0],player)\n",
    "    else:\n",
    "        print \"my hand: \"+str(state[2])\n",
    "        actP1 = controlP1.pimcSearch(state,\"p1\",20,100)\n",
    "        dominoes.playGame(state, actions[0],player) \n",
    "        iaPlay(state,\"p2\")\n",
    "    r1 += dominoes.reward(state,\"p1\")\n",
    "    r2 += dominoes.reward(state,\"p2\")\n",
    "\n",
    "    #print \"State after both plays: \"+str(state)\n",
    "    print \"field after both plays: \"+str(state[3])\n",
    "if(state[0]==4):\n",
    "    print \"IA Wins\"\n",
    "else:\n",
    "    print \"I Win\"\n",
    "\n",
    "print \"My Game reward: \"+str(r2)\n",
    "print \"IA Game reward: \"+str(r1)\n",
    "cr1 +=r1\n",
    "cr2 +=r2\n",
    "print \"IA Cumulative reward: \"+str(cr1)\n",
    "print \"My Cumulative reward: \"+str(cr2)\n",
    "print state\n",
    "print \"END OF GAME \"+str(count)\n",
    "print \"XXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "\n",
    "print \"Player1 winnings: \"+str(P1Wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Draw and Block Tester\n",
    "dominoes = Domino(0,0,0,0,True,\"Draw\")\n",
    "state = [1,[(6,6),(0,3),(0,0)],[(0,2),(2,2),(3,3)],[],-1,-1,False,False,[(6,5),(1,4),(2,4)]]\n",
    "actions = dominoes.possibleActions(state,\"p1\")\n",
    "print state,actions\n",
    "print \"P1 plays 6,6 from its hand\"\n",
    "dominoes.playAction(state,actions[0],\"p1\")\n",
    "actions = dominoes.possibleActions(state,\"p2\")\n",
    "print state,actions\n",
    "print \"P2 plays 6,5 from boneyard\"\n",
    "dominoes.playAction(state,actions[0],\"p2\")\n",
    "actions = dominoes.possibleActions(state,\"p1\")\n",
    "print state,actions\n",
    "print \"P1 does not have playable pieces on hand and boneyard, take all boneyard pieces, and is blocked\"\n",
    "dominoes.playAction(state,actions[0],\"p1\")\n",
    "print state,actions\n",
    "print \"P2 too does not have playable pieces. Both blocked and GameOver\"\n",
    "actions = dominoes.possibleActions(state,\"p2\")\n",
    "dominoes.playAction(state,actions[0],\"p2\")\n",
    "print state,actions\n",
    "print \"P2 wins! (lower score than P1)\"\n",
    "r1 = dominoes.reward(state,\"p1\")\n",
    "r2 = dominoes.reward(state,\"p2\")\n",
    "print \"P1: \"+str(r1) + \" P2: \"+str(r2)\n",
    "print state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pre-load mcst\n",
    "dominoes = Domino(0,0,0,0,False)#lost_punition para recomp de vit dos nós op serem negativos \n",
    "state = dominoes.startGame()\n",
    "featureWeights = np.load('neuralNetP1.npy')\n",
    "network = Network2()\n",
    "features = Features(featureWeights,network)\n",
    "uct = UCT(0.1)\n",
    "controlP1 = Control(0.03,features,dominoes,0.4,0,uct)\n",
    "tree = MCST()\n",
    "print state\n",
    "\n",
    "T = 0 #threshold, num de visitas necessarios para se aplicar o uct na selecao\n",
    "player = \"rootP2\"\n",
    "rootNode = Node(player,None)#sempre sera um no fantasma para as acoes possiveis\n",
    "new_state = copy.deepcopy(state)\n",
    "tree.add_node(rootNode)#nunca se esqueca de adicionar o root na arvore antes\n",
    "print featureWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pre-load normal\n",
    "dominoes = Domino(0,0,0,0,False)#lost_punition para recomp de vit dos nós op serem negativos \n",
    "state = dominoes.startGame()\n",
    "uct = UCT(0.1)\n",
    "#rootNode = Node(\"rootP2\",None)\n",
    "#tree.add_node(rootNode)\n",
    "T = 0 #threshold, num de visitas necessarios para se aplicar o uct na selecao\n",
    "featureWeights1 = np.load('neuralNetP1.npy')\n",
    "featureWeights2 = np.load('neuralNetP1.npy')\n",
    "network1 = Network35()\n",
    "network2 = Network2()\n",
    "combNetwork = CombinationalNetwork(35,network2,\"Pairwise\")\n",
    "features1 = Features(featureWeights1,combNetwork)\n",
    "features2 = Features(featureWeights2,network1)\n",
    "controlP1 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    "controlP2 = Control(0.03,features2,dominoes,0.4,0,uct)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ia vs human\n",
    "def iaPlay(state,player,flag):\n",
    "    actP1 = control.policyAct(state,player)\n",
    "    dominoes.playGame(state, actP1,player)\n",
    "    if(actP1 is None):\n",
    "        print \"IA Blocked\"\n",
    "    elif(actP1[0] is not None and flag == False):\n",
    "        print \"IA Played: \"+ str(actP1[0])+ \" on the \" + str(actP1[1])\n",
    "    elif(actP1[0] is None):\n",
    "        print \"IA Blocked\"\n",
    "    else:\n",
    "        print \"IA Played: \"+ str(actP1[0])+\" left and \"+ str(actP1[1])+ \" right\"\n",
    "        flag = True\n",
    "        \n",
    "        #print \"State after p1 play: \"+str(state)\n",
    "    print \"Sides after p1 play: \"+str(state[4]) + \",\"+str(state[5])\n",
    "\n",
    "def myPlay(state,player,flag):\n",
    "    \n",
    "    actionss2 = dominoes.possibleActions(state,player)\n",
    "    if(actionss2[0] is None):\n",
    "        print(\"I'm Blocked!!\")\n",
    "        actP2 = control.policyAct(state,player)\n",
    "        dominoes.playGame(state, actP2,player)\n",
    "    else:\n",
    "        print(\"Choose one action: \")\n",
    "        k = 0\n",
    "        if(flag):\n",
    "            for act in actionss2:\n",
    "                print str(k)+\": \"+str(act[0])+ \" on the left and \"+str(act[1])+\" on the right\"\n",
    "                k+=1\n",
    "        else:\n",
    "            for act in actionss2:\n",
    "                print str(k)+\": \" + str(act[0])+ \" on the \"+str(act[1])\n",
    "                k+=1\n",
    "        actionPos=input(\"\")\n",
    "        dominoes.playGame(state, actionss2[actionPos],player)\n",
    "\n",
    "cr1 = 0\n",
    "r1 = 0\n",
    "cr2 = 0\n",
    "r2 = 0\n",
    "duration = 0\n",
    "count = 0\n",
    "P1Wins = 0\n",
    "firstplay = 1\n",
    "while(cr1<50 and cr2<50):\n",
    "    count+=1\n",
    "    r1 = 0\n",
    "    r2 = 0\n",
    "    state = dominoes.startGame()\n",
    "    firstplay = random.randint(0,1)\n",
    "    flag = True\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):\n",
    "            iaPlay(state,\"p1\",flag)\n",
    "            flag = False\n",
    "            print \"my hand: \"+str(state[2])\n",
    "            myPlay(state,\"p2\",flag)\n",
    "        else:\n",
    "            print \"my hand: \"+str(state[2])\n",
    "            myPlay(state,\"p2\",flag)\n",
    "            flag = False\n",
    "            iaPlay(state,\"p1\",flag)\n",
    "        r1 += dominoes.reward(state,\"p1\")\n",
    "        r2 += dominoes.reward(state,\"p2\")\n",
    "        \n",
    "        #print \"State after both plays: \"+str(state)\n",
    "        print \"field after both plays: \"+str(state[3])\n",
    "    if(state[0]==4):\n",
    "        print \"IA Wins\"\n",
    "    else:\n",
    "        print \"I Win\"\n",
    "        \n",
    "    print \"My Game reward: \"+str(r2)\n",
    "    print \"IA Game reward: \"+str(r1)\n",
    "    cr1 +=r1\n",
    "    cr2 +=r2\n",
    "    print \"IA Cumulative reward: \"+str(cr1)\n",
    "    print \"My Cumulative reward: \"+str(cr2)\n",
    "    print state\n",
    "    print \"END OF GAME \"+str(count)\n",
    "    print \"XXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    \n",
    "    \n",
    "print \"Player1 winnings: \"+str(P1Wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Complexity test1 on number of actions\n",
    "def minimaxAct(state,player):\n",
    "    copy_state = copy.deepcopy(state)\n",
    "    count = 0\n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    #print actions\n",
    "    for act in actions:\n",
    "        count+=1\n",
    "        copy_state = copy.deepcopy(state)\n",
    "        count = minmax(copy_state,act,\"p1\",count)\n",
    "    print count\n",
    "    \n",
    "def minmax(state,act,player,count):\n",
    "    #print \"Playing: \"+str(act)\n",
    "    state = dominoes.playAction(state,act,player)\n",
    "    if(state[0]==3):\n",
    "        return count\n",
    "    if(player == \"p1\"):\n",
    "        player = \"p2\"\n",
    "    else:\n",
    "        player = \"p1\"   \n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    for act in actions:\n",
    "        count+=1\n",
    "        copy_state = copy.deepcopy(state)\n",
    "        count = minmax(copy_state,act,player,count)\n",
    "    return count\n",
    "        \n",
    "dominoes = Domino(0,0,0,0,True,\"Draw\")\n",
    "state = [1,[(3,0),(1,6),(1,3)],\n",
    "         [(2,4),(3,5),(1,1)],[],-1,-1,False,False,[(1,4),(3,4)]]\n",
    "minimaxAct(state,\"p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manual state for test\n",
    "state = [1,[(2,4),(0,3),(0,0),(3,6),(0,1),(0,6),(5,5)],[(2,2),(6,6),(1,5),(1,4),(1,6),(0,2),(1,3)],[],-1,-1,False,False]\n",
    "new_state = copy.deepcopy(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manual state2 for test\n",
    "#Aqui é testado o uso do mcst num jogo já em percurso\n",
    "state = [1,[(2,4),(0,3),(0,0)],[(0,2),(2,2),(3,3)],[],-1,-1,False,False]\n",
    "actions = dominoes.possibleActions(state,\"p1\")\n",
    "dominoes.playGame(state, actions[0],\"p1\")#jogue 0,0\n",
    "#actions = dominoes.possibleActions(state,\"p2\")#jogue 2,0\n",
    "#dominoes.playGame(state, actions[0],\"p2\")\n",
    "#resultados previstos: escolhe 2,4 como proxima acao, pois tem maior\n",
    "#recompensa(10), evitando 0,3 que gera 2 caminhos de recompensa 4 e 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manual state3 for test\n",
    "#o branch do 2,4 logo domina com rec 0.2, mas ele n deixa de tentar o branch 3,5\n",
    "# que tem possíveis recompensas 0.18 e 0.09 . Branch 1,1 so tem 0.09 como rec\n",
    "state = [1,[(2,4),(3,5),(1,1)],[(3,0),(1,6),(1,3)],[],-1,-1,False,False]\n",
    "new_state = copy.deepcopy(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manual state4 for test\n",
    "#ultimate minimal case, decision between victory and defeat\n",
    "state = [1,[(0,4),(2,2)],[(1,3)],[],-1,-1,False,False]\n",
    "new_state = copy.deepcopy(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test run\n",
    "tree.resetTrajectory()\n",
    "for i in range(20):\n",
    "    new_state = copy.deepcopy(state)\n",
    "    selected_node = uct.selectUCT(rootNode)\n",
    "    print \"##############################################################################\"\n",
    "    print \"node selected on iteration\"+str(i)+\": \"\n",
    "    print \"     player: \"+str(selected_node.player)+\" and act: \" +str(selected_node.act)\n",
    "    new_node = uct.expand(selected_node,new_state,dominoes)\n",
    "    print \"new expansion player: \"+str(new_node.player)+\" and act: \"+str(new_node.act)\n",
    "    r = uct.playoutRL(new_node,new_state,dominoes)\n",
    "    print \"reward on iteration\"+str(i)+\": \"+str(r)\n",
    "    uct.backpropagate(r)\n",
    "    tree.resetTrajectory()\n",
    "    print \"selected node now has value: \"+str(selected_node.valueQ)\n",
    "print \"***********************************************************************\"\n",
    "elected_node = uct.electUCT(rootNode,\"Max\")\n",
    "#deve retornar o 1 no nao expandido, o 1 filho no caso\n",
    "print \"after exhaustive search, elect node is: \"\n",
    "print \"Value: \"+str(elected_node.valueQ)+\" and act: \" +str(elected_node.act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testando a expansão do root, ate a seleção do 1 filho dele\n",
    "new_node,status = uct.expand(rootNode,new_state,dominoes)\n",
    "print str(new_node.player)+ \" act \"+str(new_node.act)#1 filho\n",
    "selected_node = uct.selectUCT(rootNode)\n",
    "tree.resetTrajectory()\n",
    "print str(selected_node.player)#deve retornar o 1 no nao expandido, o root no caso\n",
    "for i in range(6):\n",
    "    new_state = copy.deepcopy(state)\n",
    "    selected_node = uct.selectUCT(rootNode)\n",
    "    print \"node selected on iteration\"+str(i)+\": \"\n",
    "    print \"player: \"+str(selected_node.player)+\" and act: \" +str(selected_node.act)\n",
    "    new_node,status = uct.expand(selected_node,new_state,dominoes)\n",
    "    print \"new expansion player: \"+str(new_node.player)+\" and act: \"+str(new_node.act)\n",
    "    r = uct.playoutRL(new_node,new_state,dominoes)\n",
    "    print \"reward on iteration\"+str(i)+\": \"+str(r)\n",
    "    uct.backpropagate(r)\n",
    "    tree.resetTrajectory()\n",
    "    print \"root now has value: \"+str(rootNode.valueQ)\n",
    "\n",
    "selected_node = uct.selectUCT(rootNode)\n",
    "#deve retornar o 1 no nao expandido, o 1 filho no caso\n",
    "print \"after all childs expanded, new selected node is: \"\n",
    "print \"player: \"+str(selected_node.player)+\" and act: \" +str(selected_node.act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#numero de combinacoes\n",
    "count = 0\n",
    "atomFeatures = np.zeros(110)\n",
    "for i in range(0,atomFeatures.size):\n",
    "    for j in range (i,atomFeatures.size):\n",
    "        for z in range (j,atomFeatures.size):\n",
    "            count+=1\n",
    "print count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (Ubuntu, plain)",
   "language": "python",
   "name": "python2-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
