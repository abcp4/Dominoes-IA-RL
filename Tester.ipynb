{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "class Domino:\n",
    "    \n",
    "    def buy(self,hand, n, pieces):\n",
    "        i = 0\n",
    "        while i<n:\n",
    "            hand.append(pieces[i])\n",
    "            i=i+1\n",
    "        del pieces[0:n]\n",
    "        return hand\n",
    "\n",
    "    #recebe estado do jogo, retorna ações possíveis\n",
    "    def possibleActions(self,state,player):\n",
    "        status = state[0]\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        actions = []\n",
    "        index = -1\n",
    "\n",
    "        if(l_end==r_end==-1):\n",
    "            for piece in hand:\n",
    "                index +=1\n",
    "                actions.append((piece[0],piece[1],index))\n",
    "            return actions\n",
    "\n",
    "        for piece in hand:\n",
    "            index +=1\n",
    "            #peça dupla\n",
    "            if(piece[0]==piece[1]):\n",
    "                if(piece[0]==l_end):\n",
    "                    actions.append((piece[1],\"left\",index))\n",
    "                elif(piece[1]==r_end):\n",
    "                    actions.append((piece[0],\"right\",index))\n",
    "                continue\n",
    "            if(piece[0]==l_end):\n",
    "                actions.append((piece[1],\"left\",index))\n",
    "                if(l_end==r_end): #evitar duplicacao de mesmas ações na esq e dir\n",
    "                    continue\n",
    "            if(piece[1]==l_end):\n",
    "                actions.append((piece[0],\"left\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[0]==r_end):\n",
    "                actions.append((piece[1],\"right\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[1]==r_end):\n",
    "                actions.append((piece[0],\"right\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "        '''\n",
    "        pos 2 e 3 no actions se referem a nova ponta na mesa:\n",
    "        exemplo: campo 1-5 , mão : (1,2),(5,5)\n",
    "        nesse caso a peça (1,2) se encaixa no lado esquerdo, sendo\n",
    "        a nova ponta esquerda o 2. A representação será: (0,1), pois\n",
    "        0 é a posição da tupla na mão, e o 1 representa a posição na tupla,\n",
    "        que no caso é o direito\n",
    "\n",
    "        '''\n",
    "        if not actions:\n",
    "            actions.append(None)\n",
    "        return actions\n",
    "\n",
    "    def termination(self,state):#se a partida ja terminou\n",
    "        status = state[0]\n",
    "        p1_hand = state[1]\n",
    "        p2_hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if (status >= 3):\n",
    "            return True  \n",
    "        return False\n",
    "\n",
    "    def reward(self,state,player):#recompensa por estar nesse estado\n",
    "        #em caso de vitoria\n",
    "        status = state[0]\n",
    "\n",
    "        if(status == 1 or status == 2):\n",
    "            return 0\n",
    "        if(status == 3):\n",
    "            p1_hand = state[1]\n",
    "            p2_hand = state[2]\n",
    "            lighestP1Value = 13\n",
    "            lighestP2Value = 13\n",
    "            lighestP1Tile = 13\n",
    "            lighestP2Tile = 13\n",
    "            p1_total_value = 0\n",
    "            p2_total_value = 0\n",
    "            for piece in p1_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p1_total_value+=value\n",
    "            for piece in p2_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p2_total_value+=value\n",
    "            if(p1_total_value<p2_total_value):\n",
    "                state[0] = 4#player 1 venceu tendo a menor mao\n",
    "                if(player == \"p1\"):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            elif(p1_total_value>p2_total_value):\n",
    "                state[0] = 5#player 2 venceu tendo a menor mao\n",
    "                if(player == \"p1\"):\n",
    "                    return -1\n",
    "                else:\n",
    "                    return 1\n",
    "            else:#empate\n",
    "                for piece in p1_hand:\n",
    "                    if(piece[0]<lighestP1Value):\n",
    "                        lighestP1Value = piece[0]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP1Value):\n",
    "                        lighestP1Value = piece[1]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                for piece in p2_hand:\n",
    "                    if(piece[0]<lighestP2Value):\n",
    "                        lighestP2Value = piece[0]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP2Value):\n",
    "                        lighestP2Value = piece[1]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                if(lighestP1Value<lighestP2Value):\n",
    "                    state[0] = 4#player 1 venceu tendo o menor valor entre o par das pecas    \n",
    "                    if(player == \"p1\"):\n",
    "                        return 1\n",
    "                    else:\n",
    "                        return -1\n",
    "                elif(lighestP1Value>lighestP2Value):\n",
    "                    state[0] = 5#player 2 venceu tendo o menor valor entre o par das pecas\n",
    "                    if(player == \"p1\"):\n",
    "                        return -1\n",
    "                    else:\n",
    "                        return 1\n",
    "                else:\n",
    "                    if(lighestP1Tile<lighestP2Tile):#menor valor da peça como um todo\n",
    "                        state[0] = 4\n",
    "                        if(player == \"p1\"):\n",
    "                            return 1\n",
    "                        else:\n",
    "                            return -1\n",
    "                    else:#nao pode haver empate\n",
    "                        state[0] = 5\n",
    "                        if(player == \"p1\"):\n",
    "                            return -1\n",
    "                        else:\n",
    "                            return 1\n",
    "\n",
    "    def startGame(self):\n",
    "        status = 1 #1=in progress; 2=one player blocked;3=two players blocked;4/5=p1 won/p2 won\n",
    "        pieces = [(x,y) for x in range(7) for y in range(x,7)]\n",
    "        random.shuffle(pieces)\n",
    "        p1_hand = self.buy([],7,pieces)\n",
    "        p2_hand = self.buy([],7,pieces)\n",
    "        field = []\n",
    "        l_end = -1\n",
    "        r_end = -1\n",
    "        state = [status, p1_hand, p2_hand, field, l_end, r_end]\n",
    "        return state\n",
    "\n",
    "    def playGame(self,state,action,player):\n",
    "        status = state[0]\n",
    "        if(status >= 3): #jogo acabou\n",
    "            return state\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "            \n",
    "        field = state[3]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "\n",
    "        if(action[0] is None):#foi bloqueado\n",
    "            if(status == 2):\n",
    "                state[0] = 3\n",
    "            elif(status == 1):\n",
    "                state[0] = 2\n",
    "            return state\n",
    "        \n",
    "        if(status == 2): # o oponente foi bloqueado, mas eu tenho peça\n",
    "            state[0] = 1\n",
    "        p_index = action[2]  \n",
    "        if(l_end==r_end==-1):\n",
    "            orientation = \"left\"\n",
    "        else:\n",
    "            orientation = action[1]\n",
    "        p = hand[p_index]\n",
    "        field.append(p)\n",
    "        hand.remove(p)\n",
    "        if (l_end==-1 and r_end==-1):\n",
    "            l_end, r_end = p\n",
    "        elif (orientation == \"right\"):#ori e o lado desejado a manter na ponta\n",
    "            r_end=action[0]\n",
    "        elif (orientation == \"left\"):\n",
    "            l_end=action[0]\n",
    "                \n",
    "        if(player ==\"p1\"):\n",
    "            state[1] = hand\n",
    "        else:\n",
    "            state[2] = hand\n",
    "            \n",
    "        if(len(hand) ==0): #zerou a mao, acabou o jogo\n",
    "            state[0] = 3\n",
    "        state[3] = field\n",
    "        state[4] = l_end\n",
    "        state[5] = r_end\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Features:\n",
    "    \n",
    "    def __init__(self,beta,featureWeights):\n",
    "        self.data = []\n",
    "        self.beta = beta\n",
    "        self.featureWeights = featureWeights\n",
    "        self.numFeatures = featureWeights.size\n",
    "        \n",
    "    def getFeaturesWeights(self):\n",
    "        return self.featureWeights\n",
    "    \n",
    "    def setFeaturesWeights(self,featureWeights):\n",
    "        self.featureWeights = featureWeights\n",
    "    \n",
    "    def featureValues(self,state,action,player):\n",
    "        result =  np.zeros(self.numFeatures)\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if(player == \"p1\"):\n",
    "            hand = state[1]\n",
    "            handOp = state[2]\n",
    "        elif(player == \"p2\"):\n",
    "            hand = state[2]\n",
    "            handOp = state[1]\n",
    "        if(action[0]!=None):#quando nao for bloqueado    \n",
    "            pos = action[2]\n",
    "            if(l_end==r_end==-1):\n",
    "                pos = action[2]\n",
    "                l_end = action[0]\n",
    "                r_end = action[1]\n",
    "            elif(action[1]==\"left\"):\n",
    "            #substitui uma das pontas pela nova ação\n",
    "                l_end = action[0]\n",
    "            else:\n",
    "                r_end = action[0]\n",
    "            #print \"pos: \"+str(pos)\n",
    "            value =hand.pop(pos)\n",
    "        \"\"\"\n",
    "        Características a partir de informações imperfeitas.\n",
    "            Somente do que é visível a um jogador comum:\n",
    "                Campo, peças de suas mãos, quantidade de peças do oponente\n",
    "        \"\"\"\n",
    "        #valida caracteristicas de acordo com o estado submetido e as retorna\n",
    "        \n",
    "        result[0] = self.NumDouble(hand,action,l_end,r_end,lambda x: x==1)\n",
    "        result[1] = self.NumDouble(hand,action,l_end,r_end,lambda x: x==2)\n",
    "        result[2] = self.NumDouble(hand,action,l_end,r_end,lambda x: x>=3)\n",
    "        #impossibilita qualquer peça de ser jogada\n",
    "        result[3] = self.blocks(hand,action,l_end,r_end)\n",
    "        \n",
    "        result[4] = self.NumActions(hand,l_end,r_end,lambda x: x==1)\n",
    "        result[5] = self.NumActions(hand,l_end,r_end,lambda x: x==2)\n",
    "        result[6] = self.NumActions(hand,l_end,r_end,lambda x: x>=3)\n",
    "       \n",
    "        for i in range(7,14):\n",
    "            #quais peças duplas temos na mão, de 0:0 a 6:6\n",
    "            result[i] = self.hasDouble(i-7,hand)\n",
    "                \n",
    "        \"\"\"\n",
    "        Características a partir de informações perfeitas.\n",
    "        Sabe-se da mão do oponente, de toda e qualquer informação necessária\n",
    "        para se tomar uma decisão\n",
    "        \"\"\"\n",
    "        result[14] = self.blocks(handOp,action,l_end,r_end)\n",
    "        result[15] = self.NumActions(handOp,l_end,r_end,lambda x: x==1)\n",
    "        result[16] = self.NumActions(handOp,l_end,r_end,lambda x: x==2)\n",
    "        result[17] = self.NumActions(handOp,l_end,r_end,lambda x: x>=3)\n",
    "        for i in range(18,25):\n",
    "            #quais peças duplas temos na mão, de 0:0 a 6:6\n",
    "            result[i] = self.shortPiece(i-18,handOp)\n",
    "        \n",
    "        if(self.numFeatures>25):\n",
    "            result[25] = self.hasPieceValue(hand,lambda x: x>=9)\n",
    "            result[26] = self.hasPieceValue(hand,lambda x: x<=3)\n",
    "            result[27] = self.hasHandValue(hand,lambda x: x<=4)\n",
    "            result[28] = self.hasHandValue(hand,lambda x: x>=12 and x<=19)\n",
    "            result[29] = self.hasHandValue(hand,lambda x: x>=20)\n",
    "            \n",
    "            result[30] = self.hasPieceValue(handOp,lambda x: x>=9)\n",
    "            result[31] = self.hasPieceValue(handOp,lambda x: x<=3)\n",
    "            result[32] = self.hasHandValue(handOp,lambda x: x<=4)\n",
    "            result[33] = self.hasHandValue(handOp,lambda x: x>=12 and x<=19)\n",
    "            result[34] = self.hasHandValue(handOp,lambda x: x>=20)\n",
    "        \n",
    "        \n",
    "        if(action[0]!=None):\n",
    "            hand.insert(pos,value)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def NumDouble(self,hand,action,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(piece[0] == piece[1]):\n",
    "                count +=1\n",
    "        if(exp(count)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def hasDouble(self,number,hand):\n",
    "        for piece in hand:\n",
    "            if((piece[0] == piece[1]) and (piece[0] == number)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPieceValue(self,hand,exp):\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasHandValue(self,hand,exp):\n",
    "        value = 0\n",
    "        for piece in hand:\n",
    "            value += piece[0] + piece[1]\n",
    "        if(exp(value)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def blocks(self,hand,action,l_end,r_end):\n",
    "        if(action[0] is None):\n",
    "            return True\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                #se encontra alguma peça valida na mao\n",
    "                return False # então ainda não estou bloqueado\n",
    "  \n",
    "        return True #nao encontrou\n",
    "        \n",
    "    def NumActions(self,hand,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                count +=1\n",
    "        if(exp(count)):#se tem mais que o numero de peças designado\n",
    "            return True\n",
    "        return False #se tem exatamente aquele numero\n",
    "    \n",
    "    def shortPiece(self,number,handOp):\n",
    "        for piece in handOp:\n",
    "            if(piece[0]==number or piece[1]==number):\n",
    "                return False\n",
    "        return True #op n tem nenhuma peça dese tipo\n",
    "        \n",
    "          \n",
    "    def isPlayable(self,piece,l_end,r_end):#se dado a peça e as duas pontas, ela é jogavel\n",
    "        if(piece[0]==l_end or piece[0]==r_end or piece[1]==l_end or piece[1]==r_end):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    #Geracao de caracteristicas por combinacao de pares And\n",
    "    def generateAndFeatures(self,state,action,player):\n",
    "        result3 =  np.zeros(630)\n",
    "        count = 0\n",
    "        result1 = self.featureValues(state,action,player)\n",
    "        for i in range(0,result1.size):\n",
    "             for j in range (i,result1.size):\n",
    "                    if(result1[i]==1 and result1[j]==1):\n",
    "                        result3[count] = 1\n",
    "                        count+=1\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class Control:\n",
    "    def __init__(self,player,features):\n",
    "        self.player = player\n",
    "        self.features = features\n",
    "        self.featuresVector = np.zeros(35)\n",
    "    #dado o jogador, sua acao, o estado e suas caracteristicas, retorne o valor dessa acao\n",
    "    #e necessario diferencia os jogadores pois ele precisa examinar 2 hands \n",
    "    #o act n especifica de que hand e\n",
    "    def getFeatures(self):\n",
    "        return self.features\n",
    "    \n",
    "    def getPlayer(self):\n",
    "        return self.player\n",
    "    \n",
    "    def generateVector(self,state,act):\n",
    "        self.featuresVector = self.features.featureValues(state,act,self.player)\n",
    "        \n",
    "    def qValue(self,state,act):\n",
    "        featureVals = self.features.featureValues(state,act,self.player)\n",
    "        val = np.dot (self.features.getFeaturesWeights(), featureVals)    # value before action\n",
    "        return val\n",
    "\n",
    "    def eGreedyPicker(self,actions,state):\n",
    "        rand = np.random.random_sample()\n",
    "        bestValue = 0 #tomar cuidado aqui\n",
    "        cond = False\n",
    "        if(rand > e):\n",
    "            for act in actions:  \n",
    "                value = self.qValue(state,act)\n",
    "                if(not cond):\n",
    "                    bestValue = value\n",
    "                    choosenAct = act\n",
    "                    cond = True\n",
    "                if(value> bestValue):\n",
    "                    bestValue = value\n",
    "                    choosenAct = act\n",
    "        else:\n",
    "            choosenAct = random.choice(actions)\n",
    "\n",
    "        return choosenAct\n",
    "\n",
    "\n",
    "    def policyAct(self,state):\n",
    "        actions = dominoes.possibleActions(state,self.player)\n",
    "        #escolhe a partir dos valores na q-value com tecnica e-greedy\n",
    "        if(actions[0] is None):\n",
    "            return actions\n",
    "        else:\n",
    "            choosenAct = self.eGreedyPicker(actions,state)\n",
    "\n",
    "        return choosenAct\n",
    "\n",
    "    def step(self,state,act):\n",
    "        state = dominoes.playGame(state,act,self.player)                  # do selected action\n",
    "        return state\n",
    "\n",
    "    def alpha(self,vector):#calcua taxa de aprendizado de acordo com quantidade de features atuais\n",
    "        unique, counts = np.unique(vector, return_counts=True)\n",
    "        a = 0.1/(counts[1]) #constante por numero total de 1\n",
    "        return a\n",
    "    \n",
    "    def evaluate(self,state,val,act):\n",
    "        #A recompensa é dada após a ação dos 2 players\n",
    "        #não é recompensa pela ação de 1 player, mas dos dois\n",
    "        r = dominoes.reward(state,self.player)\n",
    "        featureWeights = self.features.getFeaturesWeights()\n",
    "        next_action = self.policyAct(state)                 \n",
    "        new_value = self.qValue(state,next_action)\n",
    "        target = r+ 0.9 * new_value                     # gamma = 0.9\n",
    "        delta = target - val                            # prediction error\n",
    "        featureWeights += alpha(self.featuresVector) * delta *self.featuresVector\n",
    "        self.features.setFeaturesWeights(featureWeights)\n",
    "        elements = [state,new_value,next_action]\n",
    "        return elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting weights: [-0.11032178 -0.11761096 -0.04990421  0.01879649  0.19865025  0.24216539\n",
      "  0.20578233  0.28079298 -0.01462935 -0.13267257 -0.1707254  -0.11204059\n",
      " -0.19125608 -0.14200985 -0.11387595 -0.13354416 -0.03670204  0.00718328\n",
      "  0.36521528 -0.2290457   0.09799631 -0.13859358 -0.07003191 -0.03362747\n",
      " -0.15475436 -0.10363412 -0.0324457   1.0114289  -0.39749697 -0.45473607\n",
      "  0.20954073 -0.19097426 -0.73693466  0.37793375  0.61501344]\n"
     ]
    }
   ],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "featureWeights = np.zeros(35)\n",
    "features1 = Features(1,featureWeights)\n",
    "controlP1 = Control(\"p1\",features1)\n",
    "controlP2 = Control(\"p2\",features1)\n",
    "r = 0\n",
    "duration = 0\n",
    "#self-play\n",
    "firstplay = 0\n",
    "for i in range(0,1000):\n",
    "    state = dominoes.startGame()\n",
    "    #firstplay = random.randint(0,1)#2 jogadores compartilhando a msm rede neural,mas so 1 avaliando\n",
    "\n",
    "    actP1 = controlP1.policyAct(state)  \n",
    "    val1 = controlP1.qValue(state,actP1)\n",
    "    flag = 0\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):#salva vetor de carac antes de mudar\n",
    "            controlP1.generateVector(state,actP1)\n",
    "        else:\n",
    "            controlP2.generateVector(state,actP2)\n",
    "        state = controlP1.step(state,actP1)        \n",
    "        if(flag==0):\n",
    "            actP2 = controlP2.policyAct(state)\n",
    "            flag = 1\n",
    "        val2 = controlP2.qValue(state,actP2)\n",
    "        state = controlP2.step(state,actP2)\n",
    "        if(firstplay==0):\n",
    "            state,val1,actP1 =controlP1.evaluate(state,val1,actP1)\n",
    "            actP2 = controlP2.policyAct(state)\n",
    "        else:\n",
    "            state,val2,actP2 =controlP2.evaluate(state,val2,actP2)\n",
    "            actP1 = controlP1.policyAct(state)\n",
    "   \n",
    "featureWeights = controlP1.getFeatures().getFeaturesWeights()\n",
    "print \"Resulting weights: \"+str(featureWeights)\n",
    "np.save('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNetAnd', featureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.0001  # aqui n ha aprendizagem\n",
    "featureWeightsP1 = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet4.npy')\n",
    "featureWeightsP2 = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet5.npy')\n",
    "featuresP1 = Features(1,featureWeightsP1)\n",
    "featuresP2 = Features(1,featureWeightsP2)\n",
    "\n",
    "r = 0\n",
    "duration = 0\n",
    "\n",
    "P1Wins = 0\n",
    "firstplay = 1\n",
    "for i in range(0,10000):\n",
    "    state = dominoes.startGame()\n",
    "    #firstplay = random.randint(0,1)\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):\n",
    "            actP1 = policyAct(state,\"p1\",featuresP1)         # take action by a e-greedy policy\n",
    "            state = step(state,\"p1\",actP1)\n",
    "            actP2 = policyAct(state,\"p2\",featuresP2)\n",
    "            state = step(state,\"p2\",actP2)\n",
    "        else:\n",
    "            actP2 = policyAct(state,\"p2\",featuresP2)         # take action by a e-greedy policy\n",
    "            state = step(state,\"p2\",actP2)\n",
    "            actP1 = policyAct(state,\"p1\",featuresP1)\n",
    "            state = step(state,\"p1\",actP1)\n",
    "        r = dominoes.reward(state,\"p1\")\n",
    "    if(state[0]==4):\n",
    "        P1Wins+=1\n",
    "\n",
    "\n",
    "print \"Resulting weights: \"+str(featureWeightsP1)\n",
    "#np.save('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet3', featureWeightsP1)\n",
    "print \"Player1 winnings: \"+str(P1Wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "state = dominoes.startGame()\n",
    "#print \"Initial state:\" +str(state)\n",
    "actionss1 = dominoes.possibleActions(state,\"p1\")\n",
    "actP1 = policyAct(state,\"p1\",features)         # take action by a e-greedy policy\n",
    "val1 = qValue(state,actP1,features,\"p1\")\n",
    "#for i in range(0,1): \n",
    "while(dominoes.termination(state) == False):\n",
    "        featuresVector = features.featureValues(state,actP1,\"p1\")\n",
    "        state = step(state,\"p1\",actP1)\n",
    "        print \"State after p1 play: \"+str(state[4]) + \",\"+str(state[5])\n",
    "        print \"my hand: \"+str(state[2])\n",
    "        actionss2 = dominoes.possibleActions(state,\"p2\")\n",
    "        if(actionss2[0] is None):\n",
    "            actP2 = policyAct(state,\"p2\",features)\n",
    "            state = step(state,\"p2\",actP2)\n",
    "        else:\n",
    "            actionPos=input(\"Choose Action: \"+str(actionss2))\n",
    "            state = step(state,\"p2\",actionss2[actionPos])\n",
    "        state,val1,actP1,featureWeights =evaluate(state,\"p1\",val1,actP1,features,featureWeights,featuresVector)\n",
    "        print \"State after both plays: \"+str(state[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
