{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "class Domino:\n",
    "    \n",
    "    def buy(self,hand, n, pieces):\n",
    "        i = 0\n",
    "        while i<n:\n",
    "            hand.append(pieces[i])\n",
    "            i=i+1\n",
    "        del pieces[0:n]\n",
    "        return hand\n",
    "\n",
    "    #recebe estado do jogo, retorna ações possíveis\n",
    "    def possibleActions(self,state,player):\n",
    "        status = state[0]\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        actions = []\n",
    "        index = -1\n",
    "\n",
    "        if(l_end==r_end==-1):\n",
    "            for piece in hand:\n",
    "                index +=1\n",
    "                actions.append((piece[0],piece[1],index))\n",
    "            return actions\n",
    "\n",
    "        for piece in hand:\n",
    "            index +=1\n",
    "            #peça dupla\n",
    "            if(piece[0]==piece[1]):\n",
    "                if(piece[0]==l_end):\n",
    "                    actions.append((piece[1],\"left\",index))\n",
    "                elif(piece[1]==r_end):\n",
    "                    actions.append((piece[0],\"right\",index))\n",
    "                continue\n",
    "            if(piece[0]==l_end):\n",
    "                actions.append((piece[1],\"left\",index))\n",
    "                if(l_end==r_end): #evitar duplicacao de mesmas ações na esq e dir\n",
    "                    continue\n",
    "            if(piece[1]==l_end):\n",
    "                actions.append((piece[0],\"left\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[0]==r_end):\n",
    "                actions.append((piece[1],\"right\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "            if(piece[1]==r_end):\n",
    "                actions.append((piece[0],\"right\",index))\n",
    "                if(l_end==r_end):\n",
    "                    continue\n",
    "        '''\n",
    "        pos 2 e 3 no actions se referem a nova ponta na mesa:\n",
    "        exemplo: campo 1-5 , mão : (1,2),(5,5)\n",
    "        nesse caso a peça (1,2) se encaixa no lado esquerdo, sendo\n",
    "        a nova ponta esquerda o 2. A representação será: (0,1), pois\n",
    "        0 é a posição da tupla na mão, e o 1 representa a posição na tupla,\n",
    "        que no caso é o direito\n",
    "\n",
    "        '''\n",
    "        if not actions:\n",
    "            actions.append(None)\n",
    "        return actions\n",
    "\n",
    "    def termination(self,state):#se a partida ja terminou\n",
    "        status = state[0]\n",
    "        p1_hand = state[1]\n",
    "        p2_hand = state[2]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if (status >= 3):\n",
    "            return True  \n",
    "        return False\n",
    "\n",
    "    def reward(self,state,player):#recompensa por estar nesse estado\n",
    "        #em caso de vitoria\n",
    "        status = state[0]\n",
    "\n",
    "        if(status == 1 or status == 2):\n",
    "            return 0\n",
    "        if(status == 3):\n",
    "            p1_hand = state[1]\n",
    "            p2_hand = state[2]\n",
    "            lighestP1Value = 13\n",
    "            lighestP2Value = 13\n",
    "            lighestP1Tile = 13\n",
    "            lighestP2Tile = 13\n",
    "            p1_total_value = 0\n",
    "            p2_total_value = 0\n",
    "            for piece in p1_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p1_total_value+=value\n",
    "            for piece in p2_hand:\n",
    "                value = piece[0]+piece[1]\n",
    "                p2_total_value+=value\n",
    "            if(p1_total_value<p2_total_value):\n",
    "                state[0] = 4#player 1 venceu tendo a menor mao\n",
    "                if(player == \"p1\"):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            elif(p1_total_value>p2_total_value):\n",
    "                state[0] = 5#player 2 venceu tendo a menor mao\n",
    "                if(player == \"p1\"):\n",
    "                    return -1\n",
    "                else:\n",
    "                    return 1\n",
    "            else:#empate\n",
    "                for piece in p1_hand:\n",
    "                    if(piece[0]<lighestP1Value):\n",
    "                        lighestP1Value = piece[0]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP1Value):\n",
    "                        lighestP1Value = piece[1]\n",
    "                        lighestP1Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                for piece in p2_hand:\n",
    "                    if(piece[0]<lighestP2Value):\n",
    "                        lighestP2Value = piece[0]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                    if(piece[1]<lighestP2Value):\n",
    "                        lighestP2Value = piece[1]\n",
    "                        lighestP2Tile = piece[0]+piece[1]\n",
    "                        \n",
    "                if(lighestP1Value<lighestP2Value):\n",
    "                    state[0] = 4#player 1 venceu tendo o menor valor entre o par das pecas    \n",
    "                    if(player == \"p1\"):\n",
    "                        return 1\n",
    "                    else:\n",
    "                        return -1\n",
    "                elif(lighestP1Value>lighestP2Value):\n",
    "                    state[0] = 5#player 2 venceu tendo o menor valor entre o par das pecas\n",
    "                    if(player == \"p1\"):\n",
    "                        return -1\n",
    "                    else:\n",
    "                        return 1\n",
    "                else:\n",
    "                    if(lighestP1Tile<lighestP2Tile):#menor valor da peça como um todo\n",
    "                        state[0] = 4\n",
    "                        if(player == \"p1\"):\n",
    "                            return 1\n",
    "                        else:\n",
    "                            return -1\n",
    "                    else:#nao pode haver empate\n",
    "                        state[0] = 5\n",
    "                        if(player == \"p1\"):\n",
    "                            return -1\n",
    "                        else:\n",
    "                            return 1\n",
    "\n",
    "    def startGame(self):\n",
    "        status = 1 #1=in progress; 2=one player blocked;3=two players blocked;4/5=p1 won/p2 won\n",
    "        pieces = [(x,y) for x in range(7) for y in range(x,7)]\n",
    "        random.shuffle(pieces)\n",
    "        p1_hand = self.buy([],7,pieces)\n",
    "        p2_hand = self.buy([],7,pieces)\n",
    "        field = []\n",
    "        l_end = -1\n",
    "        r_end = -1\n",
    "        state = [status, p1_hand, p2_hand, field, l_end, r_end]\n",
    "        return state\n",
    "\n",
    "    def playGame(self,state,action,player):\n",
    "        status = state[0]\n",
    "        if(status >= 3): #jogo acabou\n",
    "            return state\n",
    "        if(player ==\"p1\"):\n",
    "            hand = state[1]\n",
    "        else:\n",
    "            hand = state[2]\n",
    "            \n",
    "        field = state[3]\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "\n",
    "        if(action[0] is None):#foi bloqueado\n",
    "            if(status == 2):\n",
    "                state[0] = 3\n",
    "            elif(status == 1):\n",
    "                state[0] = 2\n",
    "            return state\n",
    "        \n",
    "        if(status == 2): # o oponente foi bloqueado, mas eu tenho peça\n",
    "            state[0] = 1\n",
    "        p_index = action[2]  \n",
    "        if(l_end==r_end==-1):\n",
    "            orientation = \"left\"\n",
    "        else:\n",
    "            orientation = action[1]\n",
    "        p = hand[p_index]\n",
    "        field.append(p)\n",
    "        hand.remove(p)\n",
    "        if (l_end==-1 and r_end==-1):\n",
    "            l_end, r_end = p\n",
    "        elif (orientation == \"right\"):#ori e o lado desejado a manter na ponta\n",
    "            r_end=action[0]\n",
    "        elif (orientation == \"left\"):\n",
    "            l_end=action[0]\n",
    "                \n",
    "        if(player ==\"p1\"):\n",
    "            state[1] = hand\n",
    "        else:\n",
    "            state[2] = hand\n",
    "            \n",
    "        if(len(hand) ==0): #zerou a mao, acabou o jogo\n",
    "            state[0] = 3\n",
    "        state[3] = field\n",
    "        state[4] = l_end\n",
    "        state[5] = r_end\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Features:\n",
    "    \n",
    "    def __init__(self,beta,featureWeights):\n",
    "        self.data = []\n",
    "        self.beta = beta\n",
    "        self.featureWeights = featureWeights\n",
    "        self.numFeatures = featureWeights.size\n",
    "        \n",
    "    def getFeaturesWeights(self):\n",
    "        return self.featureWeights\n",
    "    \n",
    "    def featureValues(self,state,action,player):\n",
    "        result =  np.zeros(self.numFeatures)\n",
    "        l_end = state[4]\n",
    "        r_end = state[5]\n",
    "        if(player == \"p1\"):\n",
    "            hand = state[1]\n",
    "            handOp = state[2]\n",
    "        elif(player == \"p2\"):\n",
    "            hand = state[2]\n",
    "            handOp = state[1]\n",
    "        if(action[0]!=None):#quando nao for bloqueado    \n",
    "            pos = action[2]\n",
    "            if(l_end==r_end==-1):\n",
    "                pos = action[2]\n",
    "                l_end = action[0]\n",
    "                r_end = action[1]\n",
    "            elif(action[1]==\"left\"):\n",
    "            #substitui uma das pontas pela nova ação\n",
    "                l_end = action[0]\n",
    "            else:\n",
    "                r_end = action[0]\n",
    "            #print \"pos: \"+str(pos)\n",
    "            value =hand.pop(pos)\n",
    "        \"\"\"\n",
    "        Características a partir de informações imperfeitas.\n",
    "            Somente do que é visível a um jogador comum:\n",
    "                Campo, peças de suas mãos, quantidade de peças do oponente\n",
    "        \"\"\"\n",
    "        #valida caracteristicas de acordo com o estado submetido e as retorna\n",
    "        \n",
    "        result[0] = self.NumDouble(hand,action,l_end,r_end,lambda x: x==1)\n",
    "        result[1] = self.NumDouble(hand,action,l_end,r_end,lambda x: x==2)\n",
    "        result[2] = self.NumDouble(hand,action,l_end,r_end,lambda x: x>=3)\n",
    "        #impossibilita qualquer peça de ser jogada\n",
    "        result[3] = self.blocks(hand,action,l_end,r_end)\n",
    "        \n",
    "        result[4] = self.NumActions(hand,l_end,r_end,lambda x: x==1)\n",
    "        result[5] = self.NumActions(hand,l_end,r_end,lambda x: x==2)\n",
    "        result[6] = self.NumActions(hand,l_end,r_end,lambda x: x>=3)\n",
    "       \n",
    "        for i in range(7,14):\n",
    "            #quais peças duplas temos na mão, de 0:0 a 6:6\n",
    "            result[i] = self.hasDouble(i-7,hand)\n",
    "                \n",
    "        \"\"\"\n",
    "        Características a partir de informações perfeitas.\n",
    "        Sabe-se da mão do oponente, de toda e qualquer informação necessária\n",
    "        para se tomar uma decisão\n",
    "        \"\"\"\n",
    "        result[14] = self.blocks(handOp,action,l_end,r_end)\n",
    "        result[15] = self.NumActions(handOp,l_end,r_end,lambda x: x==1)\n",
    "        result[16] = self.NumActions(handOp,l_end,r_end,lambda x: x==2)\n",
    "        result[17] = self.NumActions(handOp,l_end,r_end,lambda x: x>=3)\n",
    "        for i in range(18,25):\n",
    "            #quais peças duplas temos na mão, de 0:0 a 6:6\n",
    "            result[i] = self.shortPiece(i-18,handOp)\n",
    "        \n",
    "        if(self.numFeatures>25):\n",
    "            result[25] = self.hasPieceValue(hand,lambda x: x>=9)\n",
    "            result[26] = self.hasPieceValue(hand,lambda x: x<=3)\n",
    "            result[27] = self.hasHandValue(hand,lambda x: x<=4)\n",
    "            result[28] = self.hasHandValue(hand,lambda x: x>=12 and x<=19)\n",
    "            result[29] = self.hasHandValue(hand,lambda x: x>=20)\n",
    "            \n",
    "            result[30] = self.hasPieceValue(handOp,lambda x: x>=9)\n",
    "            result[31] = self.hasPieceValue(handOp,lambda x: x<=3)\n",
    "            result[32] = self.hasHandValue(handOp,lambda x: x<=4)\n",
    "            result[33] = self.hasHandValue(handOp,lambda x: x>=12 and x<=19)\n",
    "            result[34] = self.hasHandValue(handOp,lambda x: x>=20)\n",
    "        \n",
    "        \n",
    "        if(action[0]!=None):\n",
    "            hand.insert(pos,value)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def NumDouble(self,hand,action,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(piece[0] == piece[1]):\n",
    "                count +=1\n",
    "        if(exp(count)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def hasDouble(self,number,hand):\n",
    "        for piece in hand:\n",
    "            if((piece[0] == piece[1]) and (piece[0] == number)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasPieceValue(self,hand,exp):\n",
    "        for piece in hand:\n",
    "            value = piece[0] + piece[1]\n",
    "            if(exp(value)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def hasHandValue(self,hand,exp):\n",
    "        value = 0\n",
    "        for piece in hand:\n",
    "            value += piece[0] + piece[1]\n",
    "        if(exp(value)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def blocks(self,hand,action,l_end,r_end):\n",
    "        if(action[0] is None):\n",
    "            return True\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                #se encontra alguma peça valida na mao\n",
    "                return False # então ainda não estou bloqueado\n",
    "  \n",
    "        return True #nao encontrou\n",
    "        \n",
    "    def NumActions(self,hand,l_end,r_end,exp):\n",
    "        count = 0\n",
    "        for piece in hand:\n",
    "            if(self.isPlayable(piece,l_end,r_end)):\n",
    "                count +=1\n",
    "        if(exp(count)):#se tem mais que o numero de peças designado\n",
    "            return True\n",
    "        return False #se tem exatamente aquele numero\n",
    "    \n",
    "    def shortPiece(self,number,handOp):\n",
    "        for piece in handOp:\n",
    "            if(piece[0]==number or piece[1]==number):\n",
    "                return False\n",
    "        return True #op n tem nenhuma peça dese tipo\n",
    "        \n",
    "          \n",
    "    def isPlayable(self,piece,l_end,r_end):#se dado a peça e as duas pontas, ela é jogavel\n",
    "        if(piece[0]==l_end or piece[0]==r_end or piece[1]==l_end or piece[1]==r_end):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dado o jogador, sua acao, o estado e suas caracteristicas, retorne o valor dessa acao\n",
    "#e necessario diferencia os jogadores pois ele precisa examinar 2 hands \n",
    "#o act n especifica de que hand e\n",
    "def qValue(state,act,playerFeatures,player):\n",
    "    featureVals = playerFeatures.featureValues(state,act,player)\n",
    "    val = np.dot (playerFeatures.getFeaturesWeights(), featureVals)    # value before action\n",
    "    return val\n",
    "        \n",
    "def eGreedyPicker(actions,state,playerFeatures,player):\n",
    "    rand = np.random.random_sample()\n",
    "    bestValue = 0 #tomar cuidado aqui\n",
    "    cond = False\n",
    "    if(rand > e):\n",
    "        for act in actions:  \n",
    "            value = qValue(state,act,playerFeatures,player)\n",
    "            if(not cond):\n",
    "                bestValue = value\n",
    "                choosenAct = act\n",
    "                cond = True\n",
    "            if(value> bestValue):\n",
    "                bestValue = value\n",
    "                choosenAct = act\n",
    "    else:\n",
    "        choosenAct = random.choice(actions)\n",
    "  \n",
    "    return choosenAct\n",
    "\n",
    "    \n",
    "def policyAct(state,player,playerFeatures):\n",
    "    actions = dominoes.possibleActions(state,player)\n",
    "    #escolhe a partir dos valores na q-value com tecnica e-greedy\n",
    "    if(actions[0] is None):\n",
    "        return actions\n",
    "    else:\n",
    "        choosenAct = eGreedyPicker(actions,state,playerFeatures,player)\n",
    "    \n",
    "    return choosenAct\n",
    "\n",
    "def step(state,player,act):\n",
    "    state = dominoes.playGame(state,act,player)                  # do selected action\n",
    "    #print player + \" played action : \"+str(act)\n",
    "    #print \"now state is \" + str(state)\n",
    "    return state\n",
    "\n",
    "def alpha(vector):#calcua taxa de aprendizado de acordo com quantidade de features atuais\n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    a = 0.1/(counts[1]) #constante por numero total de 1\n",
    "    return a\n",
    "def evaluate(state,player,val,act,playerFeatures,featureWeights,featuresVector):\n",
    "    #A recompensa é dada após a ação dos 2 players\n",
    "    #não é recompensa pela ação de 1 player, mas dos dois\n",
    "    r = dominoes.reward(state,player)   \n",
    "    next_action = policyAct(state,player,playerFeatures)                 \n",
    "    new_value = qValue(state,next_action,playerFeatures,player)\n",
    "    target = r+ 0.9 * new_value                     # gamma = 0.9\n",
    "    delta = target - val                            # prediction error\n",
    "    featureWeights += alpha(featuresVector) * delta *featuresVector\n",
    "    elements = [state,new_value,next_action,featureWeights]\n",
    "    return elements\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting weights: [-0.17547866 -0.15514322 -0.08801508  0.9467075   0.99171707  0.98396033\n",
      "  0.94567308  0.25196739 -0.00861509 -0.19492712 -0.20133019 -0.16652455\n",
      " -0.09293869 -0.22839716 -0.05607874  0.02569663 -0.09296799 -0.17399491\n",
      "  0.51315692  0.02823395  0.14092833  0.26141676  0.20065675  0.20482948\n",
      "  0.26932737  0.05453038 -0.09369467  1.59841699 -0.55086085 -0.88405523\n",
      "  0.39709503 -0.16369437 -1.08321733  0.61540473  1.13285755]\n"
     ]
    }
   ],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "featureWeights = np.zeros(35)\n",
    "features = Features(1,featureWeights)\n",
    "r = 0\n",
    "duration = 0\n",
    "#self-play\n",
    "firstplay = 0\n",
    "for i in range(0,10000):\n",
    "    state = dominoes.startGame()\n",
    "    #firstplay = random.randint(0,1)#2 jogadores compartilhando a msm rede neural,mas so 1 avaliando\n",
    "\n",
    "    #print \"Game \"+str(i)\n",
    "    #print \"Initial state:\" +str(state)\n",
    "    #actionss1 = dominoes.possibleActions(state,\"p1\")\n",
    "    actP1 = policyAct(state,\"p1\",features)         # take action by a e-greedy policy\n",
    "    val1 = qValue(state,actP1,features,\"p1\")\n",
    "    flag = 0\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):#salva vetor de carac antes de mudar\n",
    "            featuresVector1 = features.featureValues(state,actP1,\"p1\")\n",
    "        else:\n",
    "            featuresVector2 = features.featureValues(state,actP2,\"p2\")  \n",
    "        state = step(state,\"p1\",actP1)\n",
    "        ##print \"valid features are: \"+str(featuresVector)\n",
    "        \n",
    "        if(flag==0):\n",
    "            actP2 = policyAct(state,\"p2\",features)\n",
    "            flag = 1\n",
    "        val2 = qValue(state,actP2,features,\"p2\")\n",
    "        state = step(state,\"p2\",actP2)\n",
    "\n",
    "        #pega recompensas, atualiza as características e retorna novo\n",
    "        #estado, valor e proxima acao\n",
    "        if(firstplay==0):#desse modo a msm rede neural e avaliada as vezes como p1 ou p2\n",
    "            state,val1,actP1,featureWeights =evaluate(state,\"p1\",val1,actP1,features,featureWeights,featuresVector1)\n",
    "            actP2 = policyAct(state,\"p2\",features)\n",
    "        else:\n",
    "            state,val2,actP2,featureWeights =evaluate(state,\"p2\",val2,actP2,features,featureWeights,featuresVector2)\n",
    "            actP1 = policyAct(state,\"p1\",features)\n",
    "    #print \"Ending state: \"+str(state)\n",
    "    #print \"Resulting weights: \"+str(featureWeights)\n",
    "\n",
    "print \"Resulting weights: \"+str(featureWeights)\n",
    "np.save('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet5', featureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting weights: [-0.09192529 -0.20659979 -0.18093689  1.51690381  1.39831485  1.3739857\n",
      "  1.47406724  0.39218379  0.23245208 -0.12492196 -0.3718462  -0.41579741\n",
      " -0.3056125  -0.45784327 -0.13942727 -0.40643513 -0.63778834 -0.7466368\n",
      "  0.22032436  0.21868294  0.06141763  0.12064992 -0.04507749 -0.01658206\n",
      "  0.0762826  -0.27093872 -0.10939788  1.18334184 -0.36133493 -0.82256886\n",
      "  0.30248491 -0.32532836 -0.90514442  0.6470053   1.17833832]\n",
      "Player1 winnings: 3765\n"
     ]
    }
   ],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.0001  # aqui n ha aprendizagem\n",
    "featureWeightsP1 = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet4.npy')\n",
    "featureWeightsP2 = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet5.npy')\n",
    "featuresP1 = Features(1,featureWeightsP1)\n",
    "featuresP2 = Features(1,featureWeightsP2)\n",
    "\n",
    "r = 0\n",
    "duration = 0\n",
    "\n",
    "P1Wins = 0\n",
    "firstplay = 1\n",
    "for i in range(0,10000):\n",
    "    state = dominoes.startGame()\n",
    "    #firstplay = random.randint(0,1)\n",
    "    while(dominoes.termination(state) == False):\n",
    "        if(firstplay==0):\n",
    "            actP1 = policyAct(state,\"p1\",featuresP1)         # take action by a e-greedy policy\n",
    "            state = step(state,\"p1\",actP1)\n",
    "            actP2 = policyAct(state,\"p2\",featuresP2)\n",
    "            state = step(state,\"p2\",actP2)\n",
    "        else:\n",
    "            actP2 = policyAct(state,\"p2\",featuresP2)         # take action by a e-greedy policy\n",
    "            state = step(state,\"p2\",actP2)\n",
    "            actP1 = policyAct(state,\"p1\",featuresP1)\n",
    "            state = step(state,\"p1\",actP1)\n",
    "        r = dominoes.reward(state,\"p1\")\n",
    "    if(state[0]==4):\n",
    "        P1Wins+=1\n",
    "\n",
    "\n",
    "print \"Resulting weights: \"+str(featureWeightsP1)\n",
    "#np.save('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet3', featureWeightsP1)\n",
    "print \"Player1 winnings: \"+str(P1Wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18361847, -0.14694126, -0.16895149,  1.36126229,  1.14012367,\n",
       "        1.18473559,  1.15539816,  0.42505366, -0.03573196, -0.1763768 ,\n",
       "       -0.16318463, -0.32264377, -0.34663992, -0.39625977, -0.17697972,\n",
       "       -0.27019893, -0.26841684, -0.31552921,  0.48038823,  0.17342522,\n",
       "        0.05557403, -0.05822544, -0.05143658, -0.16817866, -0.17066361])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet.npy')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.05998979e-02,  -2.62488506e-02,   5.11928778e-04,\n",
       "         2.93191600e-02,   7.90449338e-03,   9.08829636e-03,\n",
       "         2.51276034e-03,   8.38678809e-02,  -1.59175326e-02,\n",
       "        -1.25717913e-02,  -1.94997232e-02,  -3.73431427e-02,\n",
       "        -4.04316603e-02,  -2.96658434e-02,   1.05623371e-02,\n",
       "        -4.68152157e-02,  -1.08597596e-04,  -7.05953077e-04,\n",
       "         1.11955643e-01,  -7.86040757e-02,  -2.07987917e-02,\n",
       "        -4.24234825e-02,  -4.65862257e-02,   4.39108207e-02,\n",
       "        -1.55914805e-02,  -7.11837625e-02,   1.15081381e-01,\n",
       "         2.06545406e-01,  -3.54756672e-02,  -5.90616192e-02,\n",
       "         5.09523125e-02,  -5.28248819e-02,  -7.41968084e-02,\n",
       "         8.74292495e-02,   6.44455089e-02])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet2.npy')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.152977  , -0.13401844, -0.21405536,  1.47267357,  1.27856345,\n",
       "        1.26356787,  1.2484516 ,  0.41680209, -0.07704588, -0.10598451,\n",
       "       -0.15727729, -0.3534382 , -0.40956067, -0.44606388, -0.1514356 ,\n",
       "       -0.23440379, -0.28698809, -0.36992121,  0.48223835,  0.15121347,\n",
       "        0.10701091,  0.17787953, -0.05757216, -0.03968698, -0.07373018])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet3.npy')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureWeightsP1 = np.load('C:\\\\Users\\\\LENOVO\\\\ReinforcementLearning\\\\neuralNet4.npy')\n",
    "features1 = Features(1,featureWeightsP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State after p1 play: 3,3\n",
      "my hand: [(5, 6), (5, 5), (1, 3), (2, 2), (2, 4), (4, 6), (0, 0)]\n",
      "Choose Action: [(1, 'left', 2)]0\n",
      "State after both plays: 1\n",
      "State after p1 play: 1,3\n",
      "my hand: [(5, 6), (5, 5), (2, 2), (2, 4), (4, 6), (0, 0)]\n",
      "State after both plays: 2\n",
      "State after p1 play: 1,0\n",
      "my hand: [(5, 6), (5, 5), (2, 2), (2, 4), (4, 6), (0, 0)]\n",
      "Choose Action: [(0, 'right', 5)]0\n",
      "State after both plays: 1\n",
      "State after p1 play: 1,0\n",
      "my hand: [(5, 6), (5, 5), (2, 2), (2, 4), (4, 6)]\n",
      "State after both plays: 4\n"
     ]
    }
   ],
   "source": [
    "dominoes = Domino()\n",
    "e = 0.03  # epsilon-greedy proportion\n",
    "state = dominoes.startGame()\n",
    "#print \"Initial state:\" +str(state)\n",
    "actionss1 = dominoes.possibleActions(state,\"p1\")\n",
    "actP1 = policyAct(state,\"p1\",features)         # take action by a e-greedy policy\n",
    "val1 = qValue(state,actP1,features,\"p1\")\n",
    "#for i in range(0,1): \n",
    "while(dominoes.termination(state) == False):\n",
    "        featuresVector = features.featureValues(state,actP1,\"p1\")\n",
    "        state = step(state,\"p1\",actP1)\n",
    "        print \"State after p1 play: \"+str(state[4]) + \",\"+str(state[5])\n",
    "        print \"my hand: \"+str(state[2])\n",
    "        actionss2 = dominoes.possibleActions(state,\"p2\")\n",
    "        if(actionss2[0] is None):\n",
    "            actP2 = policyAct(state,\"p2\",features)\n",
    "            state = step(state,\"p2\",actP2)\n",
    "        else:\n",
    "            actionPos=input(\"Choose Action: \"+str(actionss2))\n",
    "            state = step(state,\"p2\",actionss2[actionPos])\n",
    "        state,val1,actP1,featureWeights =evaluate(state,\"p1\",val1,actP1,features,featureWeights,featuresVector)\n",
    "        print \"State after both plays: \"+str(state[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
